\documentclass[11pt]{article}

% --- Packages ---
\usepackage{mathpazo}        % Loads Palatino + math support
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage{mathtools}       % For extra math tools
\usepackage{bm}              % Bold math symbols
\usepackage{enumitem}        % Better control over lists
\usepackage{geometry}        % Better margins
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue]{hyperref}
\usepackage{siunitx}         % Alignment in matrices
\usepackage{titlesec}        % Heading spacing control
\sisetup{
  table-align-text-post=false,
  table-number-alignment = center,
  table-space-text-post = none,
  tight-spacing = true,
  detect-weight = true,
  detect-family = true
}
\newcolumntype{i}[1]{S[table-format=#1]} % columns of right-aligned integers
\geometry{margin=1in}

% --- Custom commands ---
\newcommand{\F}{\mathbb{F}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\G}{\mathcal{G}}

\newcommand{\Xcal}{\mathcal{X}}  % Input space
\newcommand{\Ycal}{\mathcal{Y}}  % Output / label space
\newcommand{\Hcal}{\mathcal{H}}  % Hypothesis space
\newcommand{\Dcal}{\mathcal{D}}  % Distribution or dataset

\newcommand{\eps}{\varepsilon}
\newcommand{\del}{\partial}

\newcommand{\vect}[1]{\bm{#1}}  % Vector
\newcommand{\mat}[1]{\bm{#1}}   % Matrix

\newcommand{\abs}[1]{\left|#1\right|}                    % Absolute value
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}         % Norm
\newcommand{\set}[1]{\left\{#1\right\}}                  % Generic set
\newcommand{\inner}[2]{\left\langle#1, #2\right\rangle}  % Inner product
\newcommand{\cls}[1]{\overline{#1}}                      % Congruence class

\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\Dom}{Dom}
\DeclareMathOperator{\Null}{Null}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\id}{id}

% --- Theorem environments ---
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}

\theoremstyle{remark}
\newtheorem{remark}[definition]{Remark}
\newtheorem{example}[definition]{Example}

% --- Headings ---

% Define a new heading level (subsubsubsection)
\titleclass{\subsubsubsection}{straight}[\subsubsection]

% Set formatting: italic, own line, similar spacing
\newcounter{subsubsubsection}[subsubsection]
\renewcommand\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}

\titleformat{\subsubsubsection}
  {\normalfont\itshape} % style: italics, normal font
  {}                    % no label
  {0pt}                 % no indentation before text
  {}                    % no extra formatting before text

\titlespacing*{\subsubsubsection}
  {0pt}   % left margin
  {0.75em plus 0.25em} % space before
  {0.25em} % space after

% --- Title Info ---
\title{Mathematics for Machine Learning}
\author{}
\date{}

% --- Begin Document ---
\begin{document}

\maketitle
\vspace{1em}

\setcounter{section}{1}
\section{Linear algebra}

\begin{enumerate}

    \item[\textbf{2.1}]

          We consider \(\left(\R \setminus \{-1\}, \star \right)\), where:
          \[
              a \star b = ab + a + b \qquad a, b \in \R \setminus \{-1\}.
          \]

    \item[a.] Show that \(\left(\R \setminus \{-1\}, \star \right)\) is an Abelian group.

          \subsubsection*{Neutral element}

          We have \( 0 \in \R \setminus \{-1\} \), and for all \(a \in \R \setminus \{-1\}\):
          \[
              \begin{aligned}
                  a \star 0 = a0 + a + 0 = a, & \quad \textrm{and} \\
                  0 \star a = 0a + 0 + a = a.
              \end{aligned}
          \]

          \subsubsection*{Commutativity}

          For all \(a, b \in \R \setminus \{-1\}\), we have:
          \[
              \begin{aligned}
                  a \star b & = ab + a + b \\
                            & = ba + b + a \\
                            & = b \star a.
              \end{aligned}
          \]

          \subsubsection*{Associativity}

          For all \(a, b, c \in \R \setminus \{-1\}\), we have:
          \[
              \begin{aligned}
                  (a \star b) \star c & = (ab + a + b) \star c               \\
                                      & = (abc + ac + bc) + (ab + a + b) + c \\
                                      & = a (bc + b + c) + a + (bc + b + c)  \\
                                      & = a (b \star c) + a + (b \star c)    \\
                                      & = a \star (b \star c).
              \end{aligned}
          \]

          \subsubsection*{Existence of inverses}

          For all \(a \in \R \setminus \{-1\}\), we require the existence of an element \(b\) such that:
          \[
              \begin{alignedat}{3}
                            &  & a \star b = b \star a & \; =\; &  & 0                 \\
                  \iff\quad &  & ab + a + b            & \; =\; &  & 0                 \\
                  \iff\quad &  & b(a + 1) + a          & \; =\; &  & 0                 \\
                  \iff\quad &  & b                     & \; =\; &  & \dfrac{-a}{a + 1}
              \end{alignedat}
          \]
          This expression for \(b\) is always defined, since \(a\) cannot be \(-1\), and the denominator is always non-zero.

          \subsubsection*{Closure under \(\star\)}

          For contradiction, assume that there exist \(a, b \in \R \setminus \{-1\}\), such that:
          \[
              \begin{alignedat}{3}
                            &  & a \star b  & \; = \; &  & -1                    \\
                  \iff\quad &  & ab + a + b & \; = \; &  & -1                    \\
                  \iff\quad &  & a (1 + b)  & \; = \; &  & - (1 + b)             \\
                  \iff\quad &  & a          & \; = \; &  & -\dfrac{1 + b}{1 + b} \\
                  \iff\quad &  & a          & \; = \; &  & -1.                   \\
              \end{alignedat}
          \]

    \item[b.] In the Abelian group \(\left(\R \setminus \{-1\}, \star \right)\), solve
          \[
              3 \star x \star x = 15.
          \]

          \subsubsection*{Solution}

          We have
          \[
              \begin{alignedat}{3}
                            &  & 3 \star x \star x          &  & \; = \; & 15 \\
                  \iff\quad &  & (3x + 3 + x) \star x       &  & \; =\;  & 15 \\
                  \iff\quad &  & (4x + 3) \star x           &  & \; =\;  & 15 \\
                  \iff\quad &  & (4x^2 + 3x) + (4x + 3) + x &  & \; =\;  & 15 \\
                  \iff\quad &  & 4x^2 + 8x                  &  & \; =\;  & 12 \\
                  \iff\quad &  & x^2 + 2x -3                &  & \; =\;  & 0  \\
                  \iff\quad &  & (x + 3) (x - 1)            &  & \; =\;  & 0
              \end{alignedat}
          \]
          which yields the solutions \(x \in \{1, -3\} \subset \R \setminus \{-1\}\).

    \item[\textbf{2.1}]

          Let \(n\) be in \(\N \setminus \{0\}\). Let \(k, x\) be in \(\Z\). We define the congruence class \(\cls{k}\) of the
          integer \(k\) as the set
          \[
              \begin{aligned}
                  \cls{k} & = \{ x \in \Z \mid x - k \equiv 0 \mod n \}               \\
                          & = \{ x \in \Z \mid \exists a \in \Z: x - k = n \cdot a \}
              \end{aligned}
          \]

          We now define \(\Z / n\Z\) (also \(\Z_n\)) as the set of all congruence classes modulo \(n\).
          Euclidean division implies that this is a finite set of \(n\) elements:
          \[
              \Z_n = \left \{ \cls{0}, \cls{1}, \ldots, \cls{n - 1} \right \}.
          \]

          For all \(a, b \in \Z_n\), we define:
          \[
              \cls{a} \oplus \cls{b} = \cls{a + b}
          \]

    \item[a.] Show that (\(\Z_n, \oplus\)) is a group. Is it Abelian?

          \subsubsection*{Neutral element}

          We have \(\cls{0} \in \Z_n\) such that:
          \[
              \begin{aligned}
                  \cls{a} \oplus \cls{0} = \cls{a + 0} = \cls{a}, & \quad \textrm{and} \\
                  \cls{0} \oplus \cls{a} = \cls{0 + a} = \cls{a}.
              \end{aligned}
          \]

          \subsubsection*{Commutativity}

          For all \(\cls{a}, \cls{b} \in \Z_n\), we have:
          \[
              \begin{aligned}
                  \cls{a} \oplus \cls{b} & = \cls{a + b}             \\
                                         & = \cls{b + a}             \\
                                         & = \cls{b} \oplus \cls{a}.
              \end{aligned}
          \]

          \subsubsection*{Associativity}

          For all \(a, b, c \in \Z_n\), we have:
          \[
              \begin{aligned}
                  (\cls{a} \oplus \cls{b}) \oplus \cls{c} & = \cls{a + b} \oplus \cls{c}               \\
                                                          & = \cls{(a + b) + c}                        \\
                                                          & = \cls{a + (b + c)}                        \\
                                                          & = \cls{a} \oplus \cls{b + c}               \\
                                                          & = \cls{a} \oplus (\cls{b} \oplus \cls{c}).
              \end{aligned}
          \]

          \subsubsection*{Existence of inverses}


          For all \(\cls{a} \in \Z_n\), we require the existence of an element, \(\cls{b} \in \Z_n\), such that:
          \[
              \cls{a} \oplus \cls{b} = \cls{b} \oplus \cls{a} = \cls{0}.
          \]
          We first note that in \(\Z_n\), \(\cls{n} = \cls{0}\), and since \(n - a \in \Z\), its congruence class \(\cls{n - a} \in \Z_n\).

          Supposing then that \(\cls{b} = \cls{n - a}\), we have:
          \[
              \begin{aligned}
                  \cls{a} \oplus \cls{b} & = \cls{a} \oplus \cls{n - a} \\
                                         & = \cls{a + n - a}            \\
                                         & = \cls{n}                    \\
                                         & =       \cls{0}
              \end{aligned}
          \]
          as required, and commutativity gives us \(\cls{b} \oplus \cls{a} = \cls{0}\).

          \subsubsection*{Closure under \(\oplus\)}

          By definition, we have that
          \[
              \cls{a} \oplus \cls{b} = \cls{a + b}
          \]

          Since \(\Z_n\) is the set of congruence classes \(\cls{0}, \cls{1}, \ldots, \cls{n-1}\), and
          every integer has a unique representation modulo \(n\), then given \(a + b \in \Z\), their congruence class
          \(\cls{a + b} \in \Z_n\).

    \item[b.]

          We now define another operation \(\otimes\) for all \(\cls{a}, \cls{b} \in \Z_n\),
          \[
              \cls{a} \otimes \cls{b} = \cls{a \times b},
          \]
          where \(\times\) represents the usual multiplication in \(\Z\).

          We then have the following multiplication table for \(\Z_5 \setminus \{\cls{0}\}\) under \(\otimes\):
          \[
              \begingroup
              \renewcommand{\arraystretch}{1.3}
              \begin{array}{c|ccccc}
                  \otimes & \cls{1} & \cls{2} & \cls{3} & \cls{4} \\
                  \hline
                  \cls{1} & \cls{1} & \cls{2} & \cls{3} & \cls{4} \\
                  \cls{2} & \cls{2} & \cls{4} & \cls{1} & \cls{3} \\
                  \cls{3} & \cls{3} & \cls{1} & \cls{4} & \cls{2} \\
                  \cls{4} & \cls{4} & \cls{3} & \cls{2} & \cls{1} \\
              \end{array}
              \endgroup
          \]

          It follows that \(\Z_5 \setminus \{\cls{0}\}\) is closed under \(\otimes\), with the neutral element
          \(\cls{1}\). From the symmetry about the diagonal, we can immediately conclude that \(\otimes\) commutes.  For
          the inverse, we find the column (resp. row) that yields \(\cls{1}\) for a given row (resp. column), noting
          that \(\cls{1}\) appears in every row (resp. column).  For associativity, we note that for any three
          \(\cls{a}, \cls{b}, \cls{c} \in \Z_n \setminus \{\cls{0}\}\), both \(\cls{a} \otimes (\cls{b} \otimes
          \cls{c})\) and \((\cls{a} \otimes \cls{b}) \otimes \cls{c}\) yield the same result.  Hence, \((\Z_5 \setminus
          \{\cls{0}\}, \otimes)\) forms an Abelian group.

    \item[c.] We find that \((\Z_8 \setminus \{\cls{0}\}, \otimes)\) does not form a group, since \( \cls{2} \otimes
          \cls{4} = \cls{0} \), so closure is not satisfied.

    \item[d.] Bézout's lemma tells us that two integers \(a\) and \(b\) are relatively prime (that is, \(\gcd(a, b) = 1\)) if
          and only if there exist two integers \(u\) and \(v\) such that \(au + bv = 1\).

          Show that \((\Z_n \setminus \{\cls{0}\}, \otimes)\) is a group if and only if \(n \in \N \setminus \{0\}\) is
          prime.

          \begin{proof}[Proof]
              The neutral element is \(\cls{1} \in \Z_n \setminus \{\cls{0}\}\), given that for all \(\cls{a} \in \Z_n
              \setminus \{\cls{0}\}\):
              \[
                  \begin{aligned}
                      \cls{a} \otimes \cls{1} = \cls{a \times 1} = \cls{a} & \quad \textrm{and} \\
                      \cls{1} \otimes \cls{a} = \cls{1 \times a} = \cls{a} & .
                  \end{aligned}
              \]

              For all \(\cls{a}, \cls{b}, \cls{c} \in \Z_n \setminus \{\cls{0}\}\), we have associativity (which follows
              directly from associativity of integer multiplication):
              \[
                  \begin{aligned}
                      (\cls{a} \otimes \cls{b}) \otimes \cls{c}
                      = \cls{a \times b \times c}
                      = \cls{a} \otimes (\cls{b} \otimes \cls{c}).
                  \end{aligned}
              \]

              If \(n\) is composite, then there exist \(\cls{p}, \cls{q} \in \Z_n \setminus \{\cls{0}\}\) such that
              \(\cls{p} \otimes \cls{q} = \cls{0}\); that is, \(\Z_n \setminus \{\cls{0}\}\) contains zero divisors, and
              is not closed under \(\otimes\).  Conversely, if \(n\) is prime then no such \(\cls{p}\) or \(\cls{q}\)
              exist; \(\Z_n \setminus \{\cls{0}\}\) contains no zero divisors and is closed under \(\otimes\).

              Finally, for the existence of an inverse for all \(\cls{a} \in \Z_n \setminus \{\cls{0}\}\), we have from
              Bézout's lemma that \(a\) and \(n\) are relatively prime if and only if there exist two integers \(u\) and
              \(v\) such that \(au + nv = 1\).  Reducing both sides modulo \(n\), we have
              \[
                  au \equiv 1 \mod n,
              \]
              which tells us that \(u\) exists if and only if \(n\) is prime.  Restated:
              \[
                  \left (
                  \forall\, \cls{a} \in \Z_n \setminus \{ \cls{0} \},\quad
                  \exists\, \cls{u} \in \Z_n \setminus \{ \cls{0} \}:\quad
                  \cls{a} \otimes \cls{u} = \cls{1}
                  \right )
                  \iff n \text{ is prime}.
              \]

              Concluding, a neutral element always exists; associativity always holds; closure and the existence of
              inverses hold if and only if \(n\) is prime.  Therefore, \((\Z_n \setminus \{\cls{0}\}, \otimes)\) forms a
              group if and only if \(n\) is prime.

          \end{proof}

    \item[2.3] Consider the set \(\G\) of \(3 \times 3\) matrices, defined as follows
          \[
              \G = \left \{
              \begin{bmatrix}
                  1 & x & z \\
                  0 & 1 & y \\
                  0 & 0 & 1
              \end{bmatrix}
              \in \R^3
              \;\middle|\;
              x, y, z \in \R
              \right \}
          \]
          We define \(\cdot\) as the standard matrix multiplication.  Is \((\G, \cdot)\) a group?  If yes, is it
          Abelian?

          For \(a, b, c, x, y, z \in \R\), let:
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  1 & a & c \\
                  0 & 1 & b \\
                  0 & 0 & 1
              \end{bmatrix}
              \quad
              \mathbf{B} =
              \begin{bmatrix}
                  1 & x & z \\
                  0 & 1 & y \\
                  0 & 0 & 1
              \end{bmatrix}
          \]
          Then we have closure:
          \[
              \mathbf{B} \cdot \mathbf{A} =
              \begin{bmatrix}
                  1 & a + x & c + bx + z \\
                  0 & 1     & b + y      \\
                  0 & 0     & 1
              \end{bmatrix}
              \in \G,
          \]
          and
          \[
              \mathbf{A} \cdot \mathbf{B} =
              \begin{bmatrix}
                  1 & a + x & c + ay + z \\
                  0 & 1     & b + y      \\
                  0 & 0     & 1
              \end{bmatrix}
              \in \G.
          \]

          Associativity follows from associativity of standard matrix multiplication.  Similarly, we have the standard identity
          matrix, \(\mathbf{I} \in \G\).  For \(\mathbf{A}\) defined as above, we have its inverse:
          \[
              \mathbf{A}^{-1} =
              \begin{bmatrix}
                  1 & -a & ab - c \\
                  0 & 1  & -b     \\
                  0 & 0  & 1
              \end{bmatrix}
              \in \G.
          \]
          Verifying, we have
          \[
              \mathbf{A} \cdot \mathbf{A}^{-1} =
              \begin{bmatrix}
                  1 & a - a & ab -c -ab + c \\
                  0 & 1     & b - b         \\
                  0 & 0     & 1
              \end{bmatrix}
              =
              \begin{bmatrix}
                  1 & 0 & 0 \\
                  0 & 1 & 0 \\
                  0 & 0 & 1
              \end{bmatrix}
              = \mathbf{I}
          \]
          and
          \[
              \mathbf{A}^{-1} \cdot \mathbf{A} =
              \begin{bmatrix}
                  1 & a - a & c - ab + ab - c \\
                  0 & 1     & b - b           \\
                  0 & 0     & 1
              \end{bmatrix}
              =
              \begin{bmatrix}
                  1 & 0 & 0 \\
                  0 & 1 & 0 \\
                  0 & 0 & 1
              \end{bmatrix}
              = \mathbf{I}
          \]
          as desired.  We saw above that, in general, multiplication of \(\mathbf{A}, \mathbf{B} \in \G\) does not commute.
          We therefore conclude that \((\G, \cdot)\) is a group, but not Abelian.

          \pagebreak

    \item[2.4]
          \begin{enumerate}

              \item[a.]
                    \[
                        \begin{bmatrix}
                            1 & 2 \\
                            4 & 5 \\
                            7 & 8
                        \end{bmatrix}
                        \begin{bmatrix}
                            1 & 1 & 0 \\
                            0 & 1 & 1 \\
                            1 & 0 & 1
                        \end{bmatrix}
                        \text{ is not defined. }
                    \]

              \item[b.]
                    \[
                        \begin{bmatrix}
                            1 & 2 & 3 \\
                            4 & 5 & 6 \\
                            7 & 8 & 9
                        \end{bmatrix}
                        \begin{bmatrix}
                            1 & 1 & 0 \\
                            0 & 1 & 1 \\
                            1 & 0 & 1
                        \end{bmatrix}
                        =
                        \begin{bmatrix}
                            4  & 3  & 5  \\
                            10 & 9  & 11 \\
                            16 & 15 & 17
                        \end{bmatrix}
                    \]

              \item[c.]
                    \[
                        \begin{bmatrix}
                            1 & 1 & 0 \\
                            0 & 1 & 1 \\
                            1 & 0 & 1
                        \end{bmatrix}
                        \begin{bmatrix}
                            1 & 2 & 3 \\
                            4 & 5 & 6 \\
                            7 & 8 & 9
                        \end{bmatrix}
                        =
                        \begin{bmatrix}
                            5  & 7  & 9  \\
                            11 & 13 & 15 \\
                            8  & 10 & 12
                        \end{bmatrix}
                    \]

              \item[d.]
                    \[
                        \begin{bmatrix}
                            1 & 2 & 1  & 2  \\
                            4 & 1 & -1 & -4 \\
                        \end{bmatrix}
                        \begin{bmatrix}
                            0 & 3  \\
                            1 & -1 \\
                            2 & 1  \\
                            5 & 2
                        \end{bmatrix}
                        =
                        \begin{bmatrix}
                            14  & 2 \\
                            -21 & 2 \\
                        \end{bmatrix}
                    \]

              \item[e.]
                    \[
                        \begin{bmatrix}
                            0 & 3  \\
                            1 & -1 \\
                            2 & 1  \\
                            5 & 2
                        \end{bmatrix}
                        \begin{bmatrix}
                            1 & 2 & 1  & 2  \\
                            4 & 1 & -1 & -4 \\
                        \end{bmatrix}
                        =
                        \begin{bmatrix}
                            12 & 3  & -3 & -12 \\
                            -3 & 1  & 2  & 6   \\
                            6  & 5  & 1  & 0   \\
                            13 & 12 & 3  & 2
                        \end{bmatrix}
                    \]

          \end{enumerate}
          \pagebreak

    \item[2.5] Find the set \(\mathcal{S}\) of all solutions in \(x\) of the following inhomogeneous systems
          \(\mathbf{A}\mathbf{x} = \mathbf{b}\), where \(\mathbf{A}\) and \(\mathbf{b}\) are defined as follows:

    \item[a.]
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{}i{2}i{3}i{3}i{3}@{\;\;}}
                      1 & 1  & -1 & -1 \\
                      2 & 5  & -7 & -5 \\
                      2 & -1 & 1  & 3  \\
                      5 & 2  & -4 & 2
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{b} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;\;}}
                      1 \\ -2 \\ 4  \\ 6
                  \end{array}
              \end{bmatrix}
          \]

          Constructing the augmented matrix, \(\tilde{\mathbf{A}}\), and row-reducing,
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1  & -1 & -1 & 1  \\
                          2 & 5  & -7 & -5 & -2 \\
                          2 & -1 & 1  & 3  & 4  \\
                          5 & 2  & -4 & 2  & 6
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 - 2r_1 \\
                      r_3 \mapsto r_3 - r_2  \\
                      r_4 \mapsto r_4 - 5r_1
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1  & -1 & -1 & 1  \\
                          0 & 3  & -5 & -3 & -4 \\
                          0 & -6 & 8  & 8  & 6  \\
                          0 & -3 & 1  & 7  & 1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto r_3 + 2r_2 \\
                      r_4 \mapsto r_4 + r_2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1 & -1 & -1 & 1  \\
                          0 & 3 & -5 & -3 & -4 \\
                          0 & 0 & -2 & 2  & -2 \\
                          0 & 0 & -4 & 4  & 2
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_4 \mapsto r_4 - 2r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1 & -1 & -1 & 1  \\
                          0 & 3 & -5 & -3 & -4 \\
                          0 & 0 & -2 & 2  & -2 \\
                          0 & 0 & 0  & 0  & 6
                      \end{array}
                  \end{bmatrix}
                   & \quad
              \end{aligned}
          \]
          we find that this system \(\mathbf{A}\mathbf{x} = \mathbf{b}\), has no solutions for \(\mathbf{x}\), since the
          final row of the augmented matrix corresponds to the inconsistent equation in the entries of \(\mathbf{x}\),
          \(0 = 6\).  This tells us that \(\mathbf{b} \notin \Img(\mathbf{A})\).

          If instead we were solving the \emph{homogeneous} system, \(\mathbf{A}\mathbf{x} = \mathbf{0}\), then we
          \emph{would} find solutions for \(\mathbf{x}\), namely the null space of \(\mathbf{A}\), which is nontrivial
          since we know \(\mathbf{A}\) is less than full rank.

          Similarly, if instead \(\mathbf{b} \in \Img(\mathbf{A})\), the solutions for \(\mathbf{x}\) in
          \(\mathbf{A}\mathbf{x} = \mathbf{b}\) would form an affine subspace in \(\R^4\), namely the null space of
          \(\mathbf{A}\) shifted by any particular solution; that is
          \[
              \left \{ \mathbf{x} \in \R^4 \mid \mathbf{A}\mathbf{x} = \mathbf{b} \right \} =  \mathbf{x}_0 + \Null(\mathbf{A})
          \]

          \pagebreak

    \item[b.]
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}i{3}i{2}i{3}i{3}@{\;\;}}
                      1  & -1 & 0 & 0  & 1  \\
                      1  & 1  & 0 & -3 & 0  \\
                      2  & -1 & 0 & 1  & -1 \\
                      -1 & 2  & 0 & -2 & -1
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{b} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;\;}}
                      3 \\ 6 \\ 5 \\ -1
                  \end{array}
              \end{bmatrix}
          \]

          Constructing the augmented matrix, \(\tilde{\mathbf{A}}\), and row-reducing,
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1  & -1 & 0 & 0  & 1  & 3  \\
                          1  & 1  & 0 & -3 & 0  & 6  \\
                          2  & -1 & 0 & 1  & -1 & 5  \\
                          -1 & 2  & 0 & -2 & -1 & -1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 - r_1   \\
                      r_3 \mapsto r_3 - 2 r_2 \\
                      r_4 \mapsto r_4 + r_2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & -1 & 0 & 0  & 1  & 3  \\
                          0 & 2  & 0 & -3 & -1 & 3  \\
                          0 & -3 & 0 & 7  & -1 & -7 \\
                          0 & 3  & 0 & -5 & -1 & 5
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto (2r_3 + 3r_2) / 5 \\
                      r_4 \mapsto (r_4 + r_3) / 2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & -1 & 0 & 0  & 1  & 3  \\
                          0 & 2  & 0 & -3 & -1 & 3  \\
                          0 & 0  & 0 & 1  & -1 & -1 \\
                          0 & 0  & 0 & 1  & -1 & -1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_4 \mapsto r_4 - r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & -1 & 0 & 0  & 1  & 3  \\
                          0 & 2  & 0 & -3 & -1 & 3  \\
                          0 & 0  & 0 & 1  & -1 & -1 \\
                          0 & 0  & 0 & 0  & 0  & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                  \end{array}
              \end{aligned}
          \]

          Equivalently, in the components of \(\mathbf{x}\),
          \[
              x_1
              \begin{bmatrix}
                  \begin{array}{@{\;}i{1}@{\;}}
                      1 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_2
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      -1 \\ 2  \\ 0  \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_3
              \begin{bmatrix}
                  \begin{array}{@{\;}i{1}@{\;}}
                      0 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_4
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      0 \\ -3 \\ 1  \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_5
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      1 \\ -1 \\ -1 \\ 0
                  \end{array}
              \end{bmatrix}
              =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      3 \\ 3  \\ -1 \\ 0
                  \end{array}
              \end{bmatrix}
          \]

          This gives us the following particular solution and solution set,
          \[
              \mathbf{x}_0 =
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      6 \\ 6 \\ 0 \\ 2 \\ 3
                  \end{array}
              \end{bmatrix}
              \quad
              \left \{
              \mathbf{x} \in \R^5
              \; \middle | \;
              \mathbf{x} =
              \mathbf{x}_0
              + \lambda_1
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      0 \\ 0 \\ 1 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              +
              \lambda_2
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      1 \\ 2 \\ 0 \\ 1 \\ 1
                  \end{array}
              \end{bmatrix}
              ,\;
              \lambda_1, \lambda_2 \in \R
              \right \}
          \]

          \pagebreak

    \item[2.6] Using Gaussian elimination, find all solutions of the inhomogeneous system
          \(\mathbf{A}\mathbf{x} = \mathbf{b}\), where
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}i{1}i{1}i{1}i{1}i{1}@{\,}}
                      0 & 1 & 0 & 0 & 1 & 0 \\
                      0 & 0 & 0 & 1 & 1 & 0 \\
                      0 & 1 & 0 & 0 & 0 & 1
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{b} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\,\;}}
                      2 \\ -1 \\ 1
                  \end{array}
              \end{bmatrix}
          \]

          Constructing the augmented matrix, \(\tilde{\mathbf{A}}\), and eliminating,
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{\,}i{2}i{3}i{3}i{3}i{3}i{3}@{\quad}|i{3}@{\;\;}}
                          0 & 1 & 0 & 0 & 1 & 0 & 2  \\
                          0 & 0 & 0 & 1 & 1 & 0 & -1 \\
                          0 & 1 & 0 & 0 & 0 & 1 & 1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto r_1 - r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\,}i{2}i{3}i{3}i{3}i{3}i{3}@{\quad}|i{3}@{\;\;}}
                          0 & 1 & 0 & 0 & 1 & 0  & 2  \\
                          0 & 0 & 0 & 1 & 1 & 0  & -1 \\
                          0 & 0 & 0 & 0 & 1 & -1 & 1
                      \end{array}
                  \end{bmatrix}
              \end{aligned}
          \]
          yields the following solution set
          \[
              \left \{
              \mathbf{x} \in \R^6
              \; \middle | \;
              \mathbf{x} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\,\;}}
                      0 \\ 2  \\ 0  \\ -1 \\ 0  \\ -1
                  \end{array}
              \end{bmatrix}
              + \lambda_1
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              + \lambda_2
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              + \lambda_3
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\,\;}}
                      0 \\ 1  \\ 0  \\ 1  \\ -1 \\ 1
                  \end{array}
              \end{bmatrix}
              ,\;
              \lambda_1, \lambda_2, \lambda_3 \in \R
              \right \}
          \]

          \pagebreak

    \item[2.7] Find all solutions in \(\mathbf{x} = \begin{bmatrix}x_1 \\ x_2 \\ x_3\end{bmatrix} \in \R^3\) of the
          equation system \(\mathbf{A}\mathbf{x} = 12\mathbf{x}\), where
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  6 & 4 & 3 \\
                  6 & 0 & 9 \\
                  0 & 8 & 0
              \end{bmatrix}
              \quad \textrm{and} \quad
              \sum_{i = 1}^{3} x_i = 1.
          \]

          Rearranging, we wish to solve \((\mathbf{A} - 12 \mathbf{I}) \mathbf{x} = \mathbf{0}\), subject to the sum
          over the components of \(\mathbf{x}\). Let \(\mathbf{B} = \mathbf{A} - 12 \mathbf{I}\), then we can construct
          an augmented matrix, \(\tilde{\mathbf{B}}\), which captures all the constraints (in particular, the first row
          encodes the constraint that \(x_1 + x_2 + x_3 = 1\)):
          \[
              \begin{aligned}
                  \tilde{\mathbf{B}} =
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1  & 1   & 1   & 1 \\
                          -6 & 4   & 3   & 0 \\
                          6  & -12 & 9   & 0 \\
                          0  & 8   & -12 & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto r_3 + r_2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1  & 1  & 1   & 1 \\
                          -6 & 4  & 3   & 0 \\
                          0  & -8 & 12  & 0 \\
                          0  & 8  & -12 & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 + 6r_1 \\
                      r_3 \mapsto -r_3 / 4   \\
                      r_4 \mapsto r_4 + r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1 & 1  & 1  & 1 \\
                          0 & 10 & 9  & 6 \\
                          0 & 2  & -3 & 0 \\
                          0 & 0  & 0  & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto (r_2 - 5r_3) / 6
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1 & 1  & 1 & 1 \\
                          0 & 10 & 9 & 6 \\
                          0 & 0  & 4 & 1 \\
                          0 & 0  & 0 & 0
                      \end{array}
                  \end{bmatrix}
              \end{aligned}
          \]

          From this, we find a single solution,
          \(
          \mathbf{x}_0 =
          \dfrac{1}{8}
          \begin{bmatrix}
              3 & 3 & 2
          \end{bmatrix}^{\top}.
          \)

          Examining the last three rows of the reduced \(\tilde{\mathbf{B}}\), we can conclude that \(\rank(\mathbf{B}) =
          2\), and therefore \(\dim(\Null(\mathbf{B})) = 1\).  That is, the null space of \(\mathbf{B}\) is a line,
          which intersects with \(\mathbf{1} \in \R^3\) at a single point, \(\mathbf{x}_0\).  Specifically, we have
          \[
              \Null(\mathbf{B}) = \left \{ \mathbf{x} \in \R^3: \mathbf{x} = \lambda
              \begin{bmatrix}
                  3 \\ 3 \\ 2
              \end{bmatrix}
              ,\;
              \lambda \in \R
              \right \}.
          \]

    \item[2.8]

    \item[a.]
          Given
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  2 & 3 & 4 \\
                  3 & 4 & 5 \\
                  4 & 5 & 6
              \end{bmatrix}
          \]
          we find that \(\mathbf{A}\) has no inverse, since \(\det(\mathbf{A}) = 0\).

    \item[b.]
          Given
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  1 & 0 & 1 & 0 \\
                  0 & 1 & 1 & 0 \\
                  1 & 1 & 0 & 1 \\
                  1 & 1 & 1 & 0
              \end{bmatrix}
          \]
          we find
          \[
              \det(\mathbf{A}) = \det \left (
              \begin{bmatrix}
                      1 & 1 & 0 \\
                      1 & 0 & 1 \\
                      1 & 1 & 0
                  \end{bmatrix}
              \right )
              + \det \left (
              \begin{bmatrix}
                      0 & 0 & 1 \\
                      1 & 1 & 1 \\
                      0 & 1 & 1
                  \end{bmatrix}
              \right )
              = 0 + 1
              = 1.
          \]

          We look for solutions to the following:
          \[
              \begin{bmatrix}
                  1 & 0 & 1 & 0 \\
                  0 & 1 & 1 & 0 \\
                  1 & 1 & 0 & 1 \\
                  1 & 1 & 1 & 0
              \end{bmatrix}
              \begin{bmatrix}
                  a & b & c & d \\
                  e & f & g & h \\
                  i & j & k & l \\
                  m & n & o & p
              \end{bmatrix}
              \\
              =
              \begin{bmatrix}
                  a + i     & b + j     & c + k     & d + l     \\
                  e + i     & f + j     & g + k     & h + l     \\
                  a + e + m & b + f + n & c + g + o & d + h + p \\
                  a + e + i & b + f + j & c + g + k & d + h + l
              \end{bmatrix}
              =
              \mathbf{I}
          \]

          Solving each system of four equations in four variables gives us:
          \[
              \mathbf{A}^{-1} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}i{3}i{3}i{3}@{\;\;}}
                      0  & -1 & 0 & 1  \\
                      -1 & 0  & 0 & 1  \\
                      1  & 1  & 0 & -1 \\
                      1  & 1  & 1 & -2
                  \end{array}
              \end{bmatrix}
          \]

          Alternatively, we can augment \(\mathbf{A}\) with the identity matrix \(\mathbf{I}\) and reduce:
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\
                          0 & 1 & 1 & 0 & 0 & 1 & 0 & 0 \\
                          1 & 1 & 0 & 1 & 0 & 0 & 1 & 0 \\
                          1 & 1 & 1 & 0 & 0 & 0 & 0 & 1
                      \end{array}
                  \end{bmatrix}
                   &
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 1  & 0  & 1  & 0 & 0  & 0 \\
                          0 & 1 & 1  & 0  & 0  & 1 & 0  & 0 \\
                          0 & 1 & -1 & 1  & -1 & 0 & 1  & 0 \\
                          0 & 0 & 1  & -1 & 0  & 0 & -1 & 1
                      \end{array}
                  \end{bmatrix}
                   &
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 1 & 0  & 1 & 0 & 0  & 0  \\
                          0 & 1 & 1 & 0  & 0 & 1 & 0  & 0  \\
                          0 & 0 & 2 & -1 & 1 & 1 & -1 & 0  \\
                          0 & 0 & 0 & 1  & 1 & 1 & 1  & -2
                      \end{array}
                  \end{bmatrix}
                   &
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 0 & 0 & 0  & -1 & 0 & 1  \\
                          0 & 1 & 0 & 0 & -1 & 0  & 0 & 1  \\
                          0 & 0 & 1 & 0 & 1  & 1  & 0 & -1 \\
                          0 & 0 & 0 & 1 & 1  & 1  & 1 & -2
                      \end{array}
                  \end{bmatrix}
                   & = \begin{bmatrix}
                           \;\mathbf{I} \;|\; \mathbf{A}^{-1} \,
                       \end{bmatrix}
              \end{aligned}
          \]

          \pagebreak

    \item[2.9] Which of the following are subspaces of \(\R^3\)?

          \(A = \{ (\lambda, \lambda + \mu^3, \lambda - \mu^3 ) \mid \lambda, \mu \in \R \}\)

          \(B = \{ (\lambda^2, -\lambda^2, 0) \mid \lambda \in \R \}\)

          \(C = \{ (\eta_1, \eta_2, \eta_3) \in \R^3 \mid \eta_1 - 2 \eta_2 + 3 \eta_3 = \gamma, \; \gamma \in \R \}\)

          \(D = \{ (\kappa_1, \kappa_2, \kappa_3) \in \R^3 \mid \kappa_2 \in \Z \}\)

          \begin{enumerate}
              \item[a.] \(A\) is \emph{not} a subspace of \(\R^3\), since it is not possible to express all members of \(A\) as a
                    linear combination of a basis.

              \item[b.] \(B\) is also \emph{not} a subspace of \(\R^3\), for the same reason.

              \item[c.] \(C\) is a subspace of \(\R^3\) if and only if \(\gamma = 0\), since otherwise \(C\) does not contain the
                    origin.  In the case that \(\gamma\) \emph{does} equal \(0\), then \(C = \Span((1, 2, 1))\).

              \item[d.] \(D\) is \emph{not} a subspace of \(\R^3\), since \(D\) is not closed under scalar multiplication by
                    \(\lambda \in \R\).

          \end{enumerate}

    \item[2.10]

          \begin{enumerate}
              \item[a.] The set of vectors \(\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3\) is linearly dependent, as found
                    by constructing the matrix \(\begin{bmatrix}
                        \mathbf{x}_1 \; \mathbf{x}_2 \; \mathbf{x}_3
                    \end{bmatrix}\) and row-reducing:

                    \[
                        \begin{bmatrix}
                            \begin{array}{@{\negthinspace}i{3}i{3}i{3}@{\;\;}}
                                2  & 1  & 3  \\
                                -1 & 1  & -3 \\
                                3  & -2 & 8
                            \end{array}
                        \end{bmatrix}
                        \rightsquigarrow
                        \begin{bmatrix}
                            \begin{array}{@{\negthickspace}i{3}i{3}i{3}@{\;\;}}
                                1 & 2 & 0  \\
                                0 & 1 & -1 \\
                                0 & 0 & 0
                            \end{array}
                        \end{bmatrix}
                    \]
                    The final row of all zeros indicates the matrix has rank $2 < 3$, so the columns are linearly dependent.

              \item[b.] The set of vectors \(\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3\) is linearly independent, as found
                    by constructing the matrix \(\begin{bmatrix}
                        \mathbf{x}_1 \; \mathbf{x}_2 \; \mathbf{x}_3
                    \end{bmatrix}\) and row-reducing:
                    \[
                        \begin{bmatrix}
                            1 & 1 & 1 \\
                            2 & 1 & 0 \\
                            1 & 0 & 0 \\
                            0 & 1 & 1 \\
                            0 & 1 & 1
                        \end{bmatrix}
                        \rightsquigarrow
                        \begin{bmatrix}
                            1 & 0 & 0 \\
                            0 & 1 & 0 \\
                            0 & 0 & 1 \\
                            0 & 0 & 0 \\
                            0 & 0 & 0
                        \end{bmatrix}
                    \]
                    revealing three pivot columns. The matrix therefore has full column rank \(3\), and its column
                    vectors are linearly independent.

          \end{enumerate}

    \item[2.11] Given the following
          \[
              \mathbf{y} = \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}}1 \\ -2 \\ 5\end{array}\end{bmatrix} \quad
              \mathbf{x}_1 = \begin{bmatrix}\begin{array}{i{1}}1 \\ 1 \\ 1\end{array}\end{bmatrix} \quad
              \mathbf{x}_2 = \begin{bmatrix}\begin{array}{i{1}}1 \\ 2 \\ 3\end{array}\end{bmatrix} \quad
              \mathbf{x}_3 = \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}}2 \\ -1 \\ 1\end{array}\end{bmatrix}
          \]
          we can express
          \[
              \mathbf{y} = -6 \mathbf{x}_1 + 3 \mathbf{x}_2 + 2 \mathbf{x}_3.
          \]
          as found by forming the augmented matrix
          \[
              \begin{bmatrix}\; \mathbf{x}_1 \; \mathbf{x}_2 \; \mathbf{x}_3 \mid \mathbf{y} \;\end{bmatrix} =
              \begin{bmatrix}\mathbf{A} \mid \mathbf{y}\end{bmatrix}
          \]
          and row-reducing to \(\begin{bmatrix}\mathbf{I} \mid \mathbf{v}\end{bmatrix}\),
          where \(\mathbf{A} \mathbf{v} = \mathbf{y}\).

          \pagebreak

    \item[2.12] Consider two subspaces of \(\R^4\):
          \[
              U = \Span \left (
              \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}} 1 \\ 1 \\ -3 \\ 1  \end{array}\end{bmatrix},
              \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}} 2 \\ -1 \\ 0 \\ -1 \end{array}\end{bmatrix},
              \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}} -1 \\ 1 \\ -1 \\ 1 \end{array}\end{bmatrix}
              \right ), \quad
              V = \Span \left (
              \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}} -1 \\ -2 \\ 2 \\ 1  \end{array}\end{bmatrix},
              \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}} 2 \\ -2 \\ 0 \\ 0   \end{array}\end{bmatrix},
              \begin{bmatrix}\begin{array}{@{\negthinspace}i{3}} -3 \\ 6 \\ -2 \\ -1 \end{array}\end{bmatrix}
              \right ).
          \]
          Determine a basis of \(U \cap V\).

          If we denote the spanning vectors of \(U\) as \(u_1, u_2, u_3\), we find \(u_1 = 2 u_2 + 3 u_3\), and likewise
          denoting the spanning vectors of \(V\) as \(v_1, v_2, v_3\), we find \(v_1 = -2v_2 - v_3\), so
          \[
              U = \Span(u_2, u_3)
              \quad
              V = \Span(v_2, v_3).
          \]
          We therefore wish to find the intersection of two planes, which amounts to solving \(\mathbf{U}\mathbf{x} =
          \mathbf{V}\mathbf{y}\), where
          \[
              \mathbf{U} =
              \begin{bmatrix}
                  \begin{array}{@{\negthinspace}i{3}i{3}}
                      2  & -1 \\
                      -1 & 1  \\
                      0  & -1 \\
                      -1 & 1
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
              \quad
              \mathbf{V} =
              \begin{bmatrix}
                  \begin{array}{@{\negthinspace}i{3}i{3}}
                      2  & -3 \\
                      -2 & 6  \\
                      0  & -2 \\
                      0  & -1
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{y} = \begin{bmatrix} y_1 \\ y_2 \\ \end{bmatrix}
          \]
          We can reframe this as solving
          \[
              \begin{bmatrix}
                  \begin{array}{@{\negthinspace}i{3}i{3}i{3}i{3}}
                      2  & -1 & 2  & -3 \\
                      -1 & 1  & -2 & 6  \\
                      0  & -1 & 0  & -2 \\
                      -1 & 1  & 0  & -1
                  \end{array}
              \end{bmatrix}
              \begin{bmatrix} x_1 \\ x_2 \\ -y_1 \\ -y_2 \\ \end{bmatrix}
              = \mathbf{0}
          \]
          allowing us to row-reduce:
          \[
              \begin{aligned}
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}i{3}}
                          2  & -1 & 2  & -3 \\
                          -1 & 1  & -2 & 6  \\
                          0  & -1 & 0  & -2 \\
                          -1 & 1  & 0  & -1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto 2r_2 + r_1 \\
                      r_4 \mapsto r_4 - r_2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}i{3}}
                          2 & -1 & 2  & -3 \\
                          0 & 1  & -2 & 9  \\
                          0 & -1 & 0  & -2 \\
                          0 & 0  & 2  & -7
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto -(r_3 + r_2)
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}i{3}}
                          2 & -1 & 2  & -3 \\
                          0 & 1  & -2 & 9  \\
                          0 & 0  & 2  & -7 \\
                          0 & 0  & 2  & -7
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_1 \mapsto (r_1 + r_2) / 2 \\
                      r_2 \mapsto r_2 + r_3       \\
                      r_4 \mapsto r_4 - r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}i{3}}
                          1 & 0 & 0 & 3  \\
                          0 & 1 & 0 & 2  \\
                          0 & 0 & 2 & -7 \\
                          0 & 0 & 0 & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                  \end{array}
              \end{aligned}
          \]
          From which we can determine that \(6 u_2 + 4 u_3 = 7v_2 + 2v_3\), and that
          \[
              U \cap V = \Span \left (
              \begin{bmatrix}
                      \begin{array}{@{}i{3}@{\,\;}}
                          6 \\ 4  \\ -7  \\ -2
                      \end{array}
                  \end{bmatrix}
              \right )
          \]

    \item[2.13] Consider two subspaces \(U\) and \(V\), where \(U\) is the solution of the homogeneous equation system
          \(\mathbf{A}\mathbf{x} = \mathbf{0}\) and \(V\) is the solution of the homogeneous equation system
          \(\mathbf{B}\mathbf{x} = \mathbf{0}\), with
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{\;\;}i{1}i{3}i{3}}
                      1 & 0  & 1  \\
                      1 & -2 & -1 \\
                      2 & 1  & 3  \\
                      1 & 0  & 1  \\
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{B} =
              \begin{bmatrix}
                  \begin{array}{@{\;\;}i{1}i{3}i{3}}
                      3 & -3 & 0 \\
                      1 & 2  & 3 \\
                      7 & -5 & 2 \\
                      3 & -1 & 2 \\
                  \end{array}
              \end{bmatrix}
          \]

          \begin{enumerate}
              \item[a.] Determine the dimension of \(U\) and of \(V\).
              \item[b.] Determine the bases of \(U\) and \(V\).
              \item[c.] Determine a basis of \(U \cap V\).
          \end{enumerate}

          We first row-reduce \(\mathbf{A}\):
          \[
              \begin{alignedat}{2}
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0  & 1  \\
                          1 & -2 & -1 \\
                          2 & 1  & 3  \\
                          1 & 0  & 1  \\
                      \end{array}
                  \end{bmatrix}
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0 & 1 \\
                          0 & 1 & 1 \\
                          0 & 1 & 1 \\
                          0 & 0 & 0 \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto -\tfrac{1}{2}(r_2 - r_1) \\
                      r_3 \mapsto r_3 - 2r_1               \\
                      r_4 \mapsto r_4 - r_1
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0 & 1 \\
                          0 & 1 & 1 \\
                          0 & 0 & 0 \\
                          0 & 0 & 0 \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto r_3 - r_2
                  \end{array}
              \end{alignedat}
          \]
          finding that \(\mathbf{A}\) is of rank 2.  Since \(\mathbf{x} \in \R^3\), we have
          \(\dim(U) = 3 - \rank(\mathbf{A}) = 1\).

          Row-reducing \(\mathbf{B}\),
          \[
              \begin{alignedat}{2}
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          3 & -3 & 0 \\
                          1 & 2  & 3 \\
                          7 & -5 & 2 \\
                          3 & -1 & 2 \\
                      \end{array}
                  \end{bmatrix}
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & -7 & -6 \\
                          1 & 2  & 3  \\
                          0 & 1  & 1  \\
                          0 & 1  & 1  \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_1 \mapsto r_1 - 2r_2          \\
                      r_3 \mapsto -(r_3 - 2r_1 - r_2) \\
                      r_4 \mapsto \tfrac{1}{2} (r_4 - r_1)
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0 & 1 \\
                          1 & 0 & 1 \\
                          0 & 1 & 1 \\
                          0 & 0 & 0 \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_1 \mapsto r_1 + 7r_3 \\
                      r_2 \mapsto r_2 - 2r_3 \\
                      r_4 \mapsto r_4 - r_3
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0 & 1 \\
                          0 & 1 & 1 \\
                          0 & 0 & 0 \\
                          0 & 0 & 0 \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_3 \\
                      r_3 \mapsto r_2 - r_1
                  \end{array}
              \end{alignedat}
          \]
          we find an identical reduced form as we found for \(\mathbf{A}\), so likewise \(\dim(V) = 1\).

          We therefore find the same solution set to both systems, \(\mathbf{A}\mathbf{x} = \mathbf{0}\) and
          \(\mathbf{B}\mathbf{x} = \mathbf{0}\),
          \[
              \left \{
              \mathbf{x} \in \R^3 \;\middle |\; \mathbf{x} = \lambda
              \begin{bmatrix}
                  \begin{array}{@{}i{3}}
                      1 \\ 1 \\ -1
                  \end{array}
              \end{bmatrix}
              ,\;
              \lambda \in \R
              \right \}
          \]

          Finally, we conclude that \(U\) and \(V\) span the same line in \(\R^3\):
          \[
              U = V = U \cap V = \Span \left (
              \begin{bmatrix}
                      \begin{array}{@{}i{3}}
                          1 \\ 1 \\ -1
                      \end{array}
                  \end{bmatrix}
              \right )
          \]

    \item[2.14] Consider two subspaces \(U\) and \(V\), where \(U\) is spanned by the columns of \(\mathbf{A}\), and
          \(V\) is spanned by the columns of \(\mathbf{B}\), with
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{\;\;}i{1}i{3}i{3}}
                      1 & 0  & 1  \\
                      1 & -2 & -1 \\
                      2 & 1  & 3  \\
                      1 & 0  & 1  \\
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{B} =
              \begin{bmatrix}
                  \begin{array}{@{\;\;}i{1}i{3}i{3}}
                      3 & -3 & 0 \\
                      1 & 2  & 3 \\
                      7 & -5 & 2 \\
                      3 & -1 & 2 \\
                  \end{array}
              \end{bmatrix}
          \]

          \begin{enumerate}
              \item[a.] Determine the dimension of \(U\) and of \(V\).
              \item[b.] Determine the bases of \(U\) and \(V\).
              \item[c.] Determine a basis of \(U \cap V\).
          \end{enumerate}

          We can reformulate \(\mathbf{A}\) as follows
          \[
              \begin{alignedat}{2}
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0  & 1  \\
                          1 & -2 & -1 \\
                          2 & 1  & 3  \\
                          1 & 0  & 1  \\
                      \end{array}
                  \end{bmatrix}
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0  & 0  \\
                          1 & -2 & -2 \\
                          2 & 1  & 1  \\
                          1 & 0  & 0  \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      c_3 \mapsto c_3 - c_1
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          1 & 0  & 0 \\
                          5 & -2 & 0 \\
                          0 & 1  & 0 \\
                          1 & 0  & 0 \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      c_1 \mapsto c_1 - 2c_2 \\
                      c_3 \mapsto c_3 - c_2  \\
                  \end{array}
              \end{alignedat}
          \]
          which is to say, \(\dim(U) = 2\), since the two remaining non-zero columns cannot be expressed as a
          linear combination of each other, and these two column vectors form a basis of \(U\).

          Similarly, we reformulate \(\mathbf{B}\) as follows
          \[
              \begin{alignedat}{2}
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          3 & -3 & 0 \\
                          1 & 2  & 3 \\
                          7 & -5 & 2 \\
                          3 & -1 & 2 \\
                      \end{array}
                  \end{bmatrix}
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          3 & 0 & 0 \\
                          1 & 3 & 3 \\
                          7 & 2 & 2 \\
                          3 & 2 & 2 \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      c_2 \mapsto c_2 + c_1
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}}
                          3 & 0 & 0 \\
                          1 & 3 & 0 \\
                          7 & 2 & 0 \\
                          3 & 2 & 0 \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      c_3 \mapsto c_3 - c_2
                  \end{array}
              \end{alignedat}
          \]
          and likewise, the two remaining non-zero columns form a linearly independent basis for \(V\),
          and \(\dim(V) = 2\).

          Denoting the respective column vectors of the reduced bases of \(U\) and \(V\) as \(
          \mathbf{u}_1,
          \mathbf{u}_2,
          \mathbf{v}_1,
          \mathbf{v}_2
          \), let
          \[
              \mathbf{A}' = \begin{bmatrix}\mathbf{u}_1 & \mathbf{u}_2\end{bmatrix}
              \quad
              \mathbf{B}' = \begin{bmatrix}\mathbf{v}_1 & \mathbf{v}_2\end{bmatrix}
              \quad
              \mathbf{x} = \begin{bmatrix}x_1 \\ x_2\end{bmatrix}
              \quad
              \mathbf{y} = \begin{bmatrix}y_1 \\ y_2\end{bmatrix}
          \]

          Then to determine a basis for the intersection \(U \cap V\), we can solve \(
          \mathbf{A}' \mathbf{x} -
          \mathbf{B}' \mathbf{y} =
          \mathbf{0}
          \).  That is, we look for solutions where some linear combination of the basis of \(U\) equals some linear combination of the basis of \(V\).
          We do this by forming a single augmented matrix \(\begin{bmatrix}
              \;
              \mathbf{A}'
               &
              \negthickspace
              -\mathbf{B}'
              \;
          \end{bmatrix}\) and row-reducing:
          \[
              \begin{alignedat}{2}
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{3}i{3}}
                          1 & 0  & -3 & -0 \\
                          5 & -2 & -1 & -3 \\
                          0 & 1  & -7 & -2 \\
                          1 & 0  & -3 & -2 \\
                      \end{array}
                  \end{bmatrix}
                   &
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{4}i{3}}
                          1 & 0 & -3  & -0 \\
                          0 & 2 & -14 & 3  \\
                          0 & 1 & -7  & -2 \\
                          0 & 0 & 0   & 1  \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto -(r_2 - 5 r_1) \\
                      r_4 \mapsto -\tfrac{1}{2}(r_4 - r_1)
                  \end{array}
                  \\
                   &
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{4}i{3}}
                          1 & 0 & -3 & -0 \\
                          0 & 1 & -7 & 5  \\
                          0 & 1 & -7 & -2 \\
                          0 & 0 & 0  & 1  \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 - r_3
                  \end{array}
                  \\
                   &
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{4}i{3}}
                          1 & 0 & -3 & -0 \\
                          0 & 1 & -7 & 0  \\
                          0 & 0 & 0  & 1  \\
                          0 & 0 & 0  & 1  \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 - 5r_4 \\
                      r_3 \mapsto -\tfrac{1}{7} (r_3 - r_2)
                  \end{array}
                  \\
                   &
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\;\;}i{1}i{3}i{4}i{3}}
                          1 & 0 & -3 & -0 \\
                          0 & 1 & -7 & 0  \\
                          0 & 0 & 0  & 1  \\
                          0 & 0 & 0  & 0  \\
                      \end{array}
                  \end{bmatrix}
                   &
                   & \quad
                  \begin{array}{l}
                      r_4 \mapsto r_4 - r_3
                  \end{array}
              \end{alignedat}
          \]

          Seeking to determine the intersection of the two planes \(U\) and \(V\), we find three pivot variables (\(x_1,
          x_2, y_2\)) and one free variable (\(y_1\)) as expected, and the following solution set
          \[
              \left \{
              \mathbf{v} \in \R^4 \;\middle |\; \mathbf{v} = \lambda
              \begin{bmatrix}
                  3 \\ 7 \\ 1 \\ 0
              \end{bmatrix}
              ,\;
              \lambda \in \R
              \right \}
              \quad
              \text{and}
              \quad
              U \cap V =
              \Span \left (
              \begin{bmatrix}
                      3 \\ 7 \\ 1 \\ 0
                  \end{bmatrix}
              \right )
          \]

          \pagebreak

    \item[2.15] Let \(F = \left \{ (x, y, z) \in \R^3 \mid x + y - z = 0 \right \}\) and
          \(G = \left \{ (a - b, a + b, a - 3b) \mid a, b \in \R \right \}\).

          \begin{enumerate}
              \item[a.] Show that \(F\) and \(G\) are subspaces of \(\R^3\).

              \item[b.] Calculate \(F \cap G\) without resorting to any basis vector.

              \item[c.] Find one basis for \(F\) and one basis for \(G\).  Calculate \(F \cap G\) using the basis vectors
                    previously found and check your result with the previous question.
          \end{enumerate}

          \subsubsection*{\(F\) is a subspace of \(\R^3\)}

          \subsubsubsection{Additive identity}

          \(F\) contains \((0, 0, 0)\), since \(0 + 0 - 0 = 0\).

          \subsubsubsection{Closure under scalar multiplication}

          Let \((a, b, c) \in F\), \(\lambda \in \R\).

          Then \(\lambda (a, b, c) = (\lambda a, \lambda b, \lambda c)\)

          Since \(a + b - c = 0\), it follows that \(\lambda a + \lambda b - \lambda c = 0\), as required.

          \subsubsubsection{Closure under addition}

          Let \((a, b, c), (x, y, z) \in F\).

          Then \( (a, b, c) + (x, y, z) = (a + x, b + y, c + z) \).

          Since \(a + b - c = 0\) and \(x + y - z = 0\), it follows that \((a + x) + (b + y) - (c + y) = 0\).

          \subsubsection*{\(G\) is a subspace of \(\R^3\)}

          \subsubsubsection{Additive identity}

          Given \((a - b, a + b, a - 3b) \in G\), choose \(a = b = 0\):
          \[
              (0 - 0, 0 + 0, 0 - 3 \cdot 0) = (0, 0, 0) \in G.
          \]

          \subsubsubsection{Closure under scalar multiplication}

          Let \((\alpha - \beta, \alpha + \beta, \alpha - 3\beta) \in G\), \(\lambda \in \R\).  Then
          \[
              \lambda (\alpha - \beta, \alpha + \beta, \alpha - 3\beta) = (\lambda \alpha - \lambda \beta, \lambda \alpha + \lambda \beta, \lambda \alpha - 3\lambda \beta)
          \]
          which is in \(G\) with \(a = \lambda \alpha\), \(b = \lambda \beta\).

          \subsubsubsection{Closure under addition}

          Let \((\alpha - \beta, \alpha + \beta, \alpha - 3\beta), (\gamma - \delta, \gamma + \delta, \gamma - 3\delta) \in G\).  Then
          \[
              \begin{aligned}
                         & (\alpha - \beta, \alpha + \beta, \alpha - 3\beta) + (\gamma - \delta, \gamma + \delta, \gamma - 3\delta)            \\
                  = \;\; & ((\alpha + \gamma) - (\beta + \delta), (\alpha + \gamma) + (\beta + \delta), (\alpha + \gamma) - 3(\beta + \delta))
              \end{aligned}
          \]
          which is in \(G\) with \(a = \alpha + \gamma\), \(b = \beta + \delta\).

          \subsubsection*{Intersection \(F \cap G\)}
          \[
              \begin{aligned}
                  F \cap G
                   & = \left \{
                  (a - b, a + b, a - 3b)
                  \mid (a - b) + (a + b) - (a - 3b) = 0
                  \mid a, b \in \R^3
                  \right \}
                  \\
                   & = \left \{
                  (a - b, a + b, a - 3b)
                  \mid a + 3b = 0
                  \mid a, b \in \R^3
                  \right \}
                  \\
              \end{aligned}
          \]

          \subsubsection*{Basis for \(F\)}

          Let \(\mathbf{f}_1 = (1, 0, 1)\), \(\mathbf{f}_2 = (0, 1, 1)\); both \(\mathbf{f}_1,\mathbf{f}_2 \in F\).

          Given any \((a, b, c) \in F\), \(c = a + b\), and \(a \mathbf{f}_1 + b \mathbf{f}_2 = (a, b, a + b) = (a, b, c)\).

          So \(F = \Span ( \mathbf{f}_1, \mathbf{f}_2 )\).

          \subsubsection*{Basis for \(G\)}

          Choose three members of \(G\), \((1, 2, -2), (1, 1, 1), (2, 4, 0) \in G\) (for \((a, b)\), choose \((1, 1)\), \((1, 0)\),
          \((1, 3)\), respectively).

          Form a matrix with these columns and row-reduce:
          \[
              \begin{aligned}
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}}
                          1  & 1 & 2 \\
                          2  & 1 & 4 \\
                          -2 & 1 & 0 \\
                      \end{array}
                  \end{bmatrix}
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}}
                          1 & 1 & 2 \\
                          2 & 1 & 4 \\
                          0 & 2 & 4 \\
                      \end{array}
                  \end{bmatrix}
                  \quad
                  \begin{array}{l}
                      r_3 \mapsto r_3 + r_2
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}}
                          1 & 1 & 2 \\
                          0 & 1 & 0 \\
                          0 & 2 & 4 \\
                      \end{array}
                  \end{bmatrix}
                  \quad
                  \begin{array}{l}
                      r_2 \mapsto -(r_2 - 2r_1)
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}}
                          1 & 1 & 2 \\
                          0 & 1 & 0 \\
                          0 & 0 & 1 \\
                      \end{array}
                  \end{bmatrix}
                  \quad
                  \begin{array}{l}
                      r_3 \mapsto \tfrac{1}{4} (r_3 - 2r_2)
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthinspace}i{3}i{3}i{3}}
                          1 & 0 & 0 \\
                          0 & 1 & 0 \\
                          0 & 0 & 1 \\
                      \end{array}
                  \end{bmatrix}
                  \quad
                  \begin{array}{l}
                      r_1 \mapsto r_1 - r_2 - 2r_3
                  \end{array}
              \end{aligned}
          \]
          The result has full rank, so \(G = \R^3\).

          \subsubsection*{Basis for \(F \cap G\)}

          Since \(G = \R^3\) and \(F \subset \R^3\), \(F \cap G = F = \Span(\mathbf{f}_1, \mathbf{f}_2)\).

          \subsubsection*{Revisiting \(G\)}

          Considering any \((x, y, z) \in \R^3\) and given the definition
          \[
              G = \left \{ (a - b, a + b, a - 3b) \mid a, b \in \R \right \}
          \]
          solving for \(a\) and \(b\),
          \[
              a = \tfrac{1}{2}(x + y) \qquad b = \tfrac{1}{6}(x + y - 2z)
          \]
          which are always defined.  It follows that \(G = \R^3\).

    \item[2.16] Are the following mappings linear?

          \begin{enumerate}
              \item[a.] Let \(a, b \in \R^3\).
                    \[
                        \begin{aligned}
                            \Phi : L^1([a, b]) & \rightarrow \R                            \\
                            f                  & \mapsto \Phi(f) = \int_{a}^{b} f(x) \, dx
                        \end{aligned}
                    \]
                    where \(L^1([a, b])\) denotes the set of integrable functions on \([a, b]\).

                    \textbf{Linear}.

                    \textit{Additivity}: \(\int_{a}^{b} f + g = \int_{a}^{b} f + \int_{a}^{b} g \)

                    \textit{Homogeneity}: \(\int_{a}^{b} \lambda f = \lambda \int_{a}^{b} f \)

              \item[b.]
                    \[
                        \begin{aligned}
                            \Phi : C^1 & \rightarrow C^0      \\
                            f          & \mapsto \Phi(f) = f'
                        \end{aligned}
                    \]
                    where for \(k \geq 1\), \(C^k\) denotes the set of \(k\) times continuously differentiable
                    functions, and \(C^0\) denotes the set of continuous functions.

                    \textbf{Linear}.

                    \textit{Additivity}: \((f + g)' = f' + g'\).

                    \textit{Homogeneity}: \((\lambda f)' = \lambda f'\).

              \item[c.]
                    \[
                        \begin{aligned}
                            \Phi : \R & \rightarrow \R            \\
                            x         & \mapsto \Phi(x) = \cos(x)
                        \end{aligned}
                    \]
                    \textbf{Non-linear}.  Additivity required, but in general,
                    \[
                        \cos(x + y) \neq \cos(x) + \cos(y).
                    \]

              \item[d.]
                    \[
                        \begin{aligned}
                            \Phi : \R^3 & \rightarrow \R^2 \\
                            \mathbf{x}  & \mapsto
                            \begin{bmatrix}
                                1 & 2 & 3 \\
                                1 & 4 & 3 \\
                            \end{bmatrix}
                            \mathbf{x}
                        \end{aligned}
                    \]
                    \textbf{Linear}. Matrix multiplication is linear.

              \item[e.] Let \(\theta \in [0, 2\pi]\) and
                    \[
                        \begin{aligned}
                            \Phi : \R^2 & \rightarrow \R^2 \\
                            \mathbf{x}  & \mapsto
                            \begin{bmatrix}
                                \cos(\theta)  & \sin(\theta) \\
                                -\sin(\theta) & \cos(\theta) \\
                            \end{bmatrix}
                            \mathbf{x}
                        \end{aligned}
                    \]
                    \textbf{Linear}. Matrix multiplication is linear.

          \end{enumerate}

          \pagebreak

    \item[2.17] Consider the linear mapping
          \[
              \begin{aligned}
                  \Phi & : \R^3 \rightarrow \R^4 \\
                  \Phi & \left (
                  \begin{bmatrix}
                      x_1 \\ x_2 \\ x_3
                  \end{bmatrix}
                  \right )
                  = \begin{bmatrix}
                        3x_1 + 2x_2 + x_3 \\
                        x_1 + x_2 + x_3   \\
                        x_1 - 3 x_2       \\
                        2x_1 + 3x_2 + x_3 \\
                    \end{bmatrix}
              \end{aligned}
          \]

          \begin{enumerate}
              \item[a.] Find the transformation matrix \(\mathbf{A}_\Phi\)
              \item[b.] Determine \(\rank(\mathbf{A}_\Phi)\)
              \item[c.] Compute the kernel and image of \(\Phi\).  What are \(\dim(\ker(\Phi))\) and \(\dim(\Img(\Phi))\)?
          \end{enumerate}

          \[
              \mathbf{A}_\Phi =
              \begin{bmatrix}
                  \begin{array}{@{\negthickspace}i{3}i{3}i{3}@{\;\;}}
                      3 & 2  & 1 \\
                      1 & 1  & 1 \\
                      1 & -3 & 0 \\
                      2 & 3  & 1 \\
                  \end{array}
              \end{bmatrix}
          \]
          Row-reducing, we have
          \[
              \begin{aligned}
                  \begin{bmatrix}
                      \begin{array}{@{\negthickspace}i{3}i{3}i{3}@{\;\;}}
                          3 & 2  & 1 \\
                          1 & 1  & 1 \\
                          1 & -3 & 0 \\
                          2 & 3  & 1 \\
                      \end{array}
                  \end{bmatrix}
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthickspace}i{3}i{3}i{3}@{\;\;}}
                          0 & 1  & 0 \\
                          1 & 1  & 1 \\
                          1 & -3 & 0 \\
                          0 & 1  & 0 \\
                      \end{array}
                  \end{bmatrix}
                  \quad
                  \begin{array}{l}
                      r_1 \mapsto \tfrac{1}{2} (r_1 - r_3 - r_4) \\
                      r_4 \mapsto r_4 - 2r_2
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthickspace}i{3}i{3}i{3}@{\;\;}}
                          0 & 1 & 0 \\
                          1 & 1 & 1 \\
                          1 & 0 & 0 \\
                          0 & 1 & 0 \\
                      \end{array}
                  \end{bmatrix}
                  \quad
                  \begin{array}{l}
                      r_3 \mapsto r_3 + 3r_4
                  \end{array}
                  \\
                   & \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negthickspace}i{3}i{3}i{3}@{\;\;}}
                          1 & 0 & 0 \\
                          0 & 1 & 0 \\
                          0 & 0 & 1 \\
                          0 & 0 & 0 \\
                      \end{array}
                  \end{bmatrix}
                  \quad
                  \begin{array}{l}
                      r_1 \mapsto r_3             \\
                      r_2 \mapsto r_1             \\
                      r_3 \mapsto r_2 - r_1 - r_4 \\
                      r_4 \mapsto r_4 - r_1       \\
                  \end{array}
              \end{aligned}
          \]
          So \(\mathbf{A}_\Phi\) has rank 3, \(\Ker(\Phi) = \{\mathbf{0}\} \in \R^3\).

          By the rank-nullity theorem,
          \[
              \dim(\Dom \Phi) = \dim(\Img \Phi) + \dim(\Ker \Phi)
          \]
          so \(\dim(\Ker \Phi) = 0\) gives \(\dim(\Img \Phi) = 3\).

          \pagebreak

    \item[2.18] Let \(E\) be a vector space.

          Let \(f\) and \(g\) be two automorphisms on \(E\) such that \(f \circ g = \id_E\) (the identity mapping on E).

          Show that:
          \begin{enumerate}
              \item[a.] \(\Ker(f) = \Ker(g \circ f)\)
              \item[b.] \(\Img(g) = \Img(g \circ f)\)
              \item[c.] \(\Ker(f) \cap \Img(g) = \{ \mathbf{0}_E \}\)
          \end{enumerate}

          Given \(f \circ g = \id_E\), \(g\) must be invertible, and specifically \(f\) is its inverse (and vice versa).

          It follows that \(g \circ f = \id_E\) and
          \[
              \Ker(f \circ g) = \Ker(g \circ f) = \Ker(f) = \Ker(g) = \{ \mathbf{0}_E \}
          \]
          Put another way, if either \(\Ker(f)\) or \(\Ker(g)\) were nontrivial, \(f \circ g = \id_E\) could not hold.

          By the same line of reasoning,
          \[
              \Img(f) = \Img(g) = \Img(f \circ g) = \Img(g \circ f) = E
          \]
          (each mapping and the respective compositions must map to the whole space to preserve invertibility).

          Finally,
          \[
              \Ker(f) \cap \Img(g) = \Ker(g) \cap \Img(f) = \{ \mathbf{0}_E \} \cap E = \{ \mathbf{0}_E \}.
          \]

\end{enumerate}

\end{document}

\documentclass[11pt]{article}

% --- Packages ---
\usepackage{mathpazo}        % Loads Palatino + math support
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb, amsthm, amsfonts}
\usepackage{mathtools}       % For extra math tools
\usepackage{bm}              % Bold math symbols
\usepackage{enumitem}        % Better control over lists
\usepackage{geometry}        % Better margins
\usepackage[colorlinks=true, linkcolor=blue, urlcolor=blue, citecolor=blue]{hyperref}
\usepackage{siunitx}         % Alignment in matrices
\sisetup{
  table-align-text-post=false,
  table-number-alignment = center,
  table-space-text-post = none,
  tight-spacing = true,
  detect-weight = true,
  detect-family = true
}
\newcolumntype{i}[1]{S[table-format=#1]} % columns of right-aligned integers
\geometry{margin=1in}

% --- Custom commands ---
\newcommand{\F}{\mathbb{F}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}

\newcommand{\G}{\mathcal{G}}

\newcommand{\Xcal}{\mathcal{X}}  % Input space
\newcommand{\Ycal}{\mathcal{Y}}  % Output / label space
\newcommand{\Hcal}{\mathcal{H}}  % Hypothesis space
\newcommand{\Dcal}{\mathcal{D}}  % Distribution or dataset

\newcommand{\eps}{\varepsilon}
\newcommand{\del}{\partial}

\newcommand{\vect}[1]{\bm{#1}}  % Vector
\newcommand{\mat}[1]{\bm{#1}}   % Matrix

\newcommand{\abs}[1]{\left|#1\right|}                    % Absolute value
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}         % Norm
\newcommand{\set}[1]{\left\{#1\right\}}                  % Generic set
\newcommand{\inner}[2]{\left\langle#1, #2\right\rangle}  % Inner product
\newcommand{\cls}[1]{\overline{#1}}                      % Congruence class

\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\Ker}{Ker}
\DeclareMathOperator{\Img}{Im}
\DeclareMathOperator{\Null}{Null}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\diag}{diag}

% --- Theorem environments ---
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}

\theoremstyle{remark}
\newtheorem{remark}[definition]{Remark}
\newtheorem{example}[definition]{Example}

% --- Title Info ---
\title{Mathematics for Machine Learning}
\author{}
\date{}

% --- Begin Document ---
\begin{document}

\maketitle
\vspace{1em}

\setcounter{section}{1}
\section{Linear algebra}

\begin{enumerate}

    \item[\textbf{2.1}]

          We consider \(\left(\R \setminus \{-1\}, \star \right)\), where:
          \[
              a \star b = ab + a + b \qquad a, b \in \R \setminus \{-1\}.
          \]

    \item[a.] Show that \(\left(\R \setminus \{-1\}, \star \right)\) is an Abelian group.

          \subsubsection*{Neutral element}

          We have \( 0 \in \R \setminus \{-1\} \), and for all \(a \in \R \setminus \{-1\}\):
          \[
              \begin{aligned}
                  a \star 0 = a0 + a + 0 = a, & \quad \textrm{and} \\
                  0 \star a = 0a + 0 + a = a.
              \end{aligned}
          \]

          \subsubsection*{Commutativity}

          For all \(a, b \in \R \setminus \{-1\}\), we have:
          \[
              \begin{aligned}
                  a \star b & = ab + a + b \\
                            & = ba + b + a \\
                            & = b \star a.
              \end{aligned}
          \]

          \subsubsection*{Associativity}

          For all \(a, b, c \in \R \setminus \{-1\}\), we have:
          \[
              \begin{aligned}
                  (a \star b) \star c & = (ab + a + b) \star c               \\
                                      & = (abc + ac + bc) + (ab + a + b) + c \\
                                      & = a (bc + b + c) + a + (bc + b + c)  \\
                                      & = a (b \star c) + a + (b \star c)    \\
                                      & = a \star (b \star c).
              \end{aligned}
          \]

          \subsubsection*{Existence of inverse}

          For all \(a \in \R \setminus \{-1\}\), we require the existence of an element \(b\) such that:
          \[
              \begin{alignedat}{3}
                            &  & a \star b = b \star a & \; =\; &  & 0                 \\
                  \iff\quad &  & ab + a + b            & \; =\; &  & 0                 \\
                  \iff\quad &  & b(a + 1) + a          & \; =\; &  & 0                 \\
                  \iff\quad &  & b                     & \; =\; &  & \dfrac{-a}{a + 1}
              \end{alignedat}
          \]
          This expression for \(b\) is always defined, since \(a\) cannot be \(-1\), and the denominator is always non-zero.

          \subsubsection*{Closure under \(\star\)}

          For contradiction, assume that there exist \(a, b \in \R \setminus \{-1\}\), such that:
          \[
              \begin{alignedat}{3}
                            &  & a \star b  & \; = \; &  & -1                    \\
                  \iff\quad &  & ab + a + b & \; = \; &  & -1                    \\
                  \iff\quad &  & a (1 + b)  & \; = \; &  & - (1 + b)             \\
                  \iff\quad &  & a          & \; = \; &  & -\dfrac{1 + b}{1 + b} \\
                  \iff\quad &  & a          & \; = \; &  & -1.                   \\
              \end{alignedat}
          \]

    \item[b.] In the Abelian group \(\left(\R \setminus \{-1\}, \star \right)\), solve
          \[
              3 \star x \star x = 15.
          \]

          \subsubsection*{Solution}

          We have
          \[
              \begin{alignedat}{3}
                            &  & 3 \star x \star x          &  & \; = \; & 15 \\
                  \iff\quad &  & (3x + 3 + x) \star x       &  & \; =\;  & 15 \\
                  \iff\quad &  & (4x + 3) \star x           &  & \; =\;  & 15 \\
                  \iff\quad &  & (4x^2 + 3x) + (4x + 3) + x &  & \; =\;  & 15 \\
                  \iff\quad &  & 4x^2 + 8x                  &  & \; =\;  & 12 \\
                  \iff\quad &  & x^2 + 2x -3                &  & \; =\;  & 0  \\
                  \iff\quad &  & (x + 3) (x - 1)            &  & \; =\;  & 0
              \end{alignedat}
          \]
          which yields the solutions \(x \in \{1, -3\} \subset \R \setminus \{-1\}\).

    \item[\textbf{2.1}]

          Let \(n\) be in \(\N \setminus \{0\}\). Let \(k, x\) be in \(\Z\). We define the congruence class \(\cls{k}\) of the
          integer \(k\) as the set
          \[
              \begin{aligned}
                  \cls{k} & = \{ x \in \Z \mid x - k \equiv 0 \mod n \}               \\
                          & = \{ x \in \Z \mid \exists a \in \Z: x - k = n \cdot a \}
              \end{aligned}
          \]

          We now define \(\Z / n\Z\) (also \(\Z_n\)) as the set of all congruence classes modulo \(n\).
          Euclidean division implies that this is a finite set of \(n\) elements:
          \[
              \Z_n = \left \{ \cls{0}, \cls{1}, \ldots, \cls{n - 1} \right \}.
          \]

          For all \(a, b \in \Z_n\), we define:
          \[
              \cls{a} \oplus \cls{b} = \cls{a + b}
          \]

    \item[a.] Show that (\(\Z_n, \oplus\)) is a group. Is it Abelian?

          \subsubsection*{Neutral element}

          We have \(\cls{0} \in \Z_n\) such that:
          \[
              \begin{aligned}
                  \cls{a} \oplus \cls{0} = \cls{a + 0} = \cls{a}, & \quad \textrm{and} \\
                  \cls{0} \oplus \cls{a} = \cls{0 + a} = \cls{a}.
              \end{aligned}
          \]

          \subsubsection*{Commutativity}

          For all \(\cls{a}, \cls{b} \in \Z_n\), we have:
          \[
              \begin{aligned}
                  \cls{a} \oplus \cls{b} & = \cls{a + b}             \\
                                         & = \cls{b + a}             \\
                                         & = \cls{b} \oplus \cls{a}.
              \end{aligned}
          \]

          \subsubsection*{Associativity}

          For all \(a, b, c \in \Z_n\), we have:
          \[
              \begin{aligned}
                  (\cls{a} \oplus \cls{b}) \oplus \cls{c} & = \cls{a + b} \oplus \cls{c}               \\
                                                          & = \cls{(a + b) + c}                        \\
                                                          & = \cls{a + (b + c)}                        \\
                                                          & = \cls{a} \oplus \cls{b + c}               \\
                                                          & = \cls{a} \oplus (\cls{b} \oplus \cls{c}).
              \end{aligned}
          \]

          \subsubsection*{Existence of inverse}


          For all \(\cls{a} \in \Z_n\), we require the existence of an element, \(\cls{b} \in \Z_n\), such that:
          \[
              \cls{a} \oplus \cls{b} = \cls{b} \oplus \cls{a} = \cls{0}.
          \]
          We first note that in \(\Z_n\), \(\cls{n} = \cls{0}\), and since \(n - a \in \Z\), its congruence class \(\cls{n - a} \in \Z_n\).

          Supposing then that \(\cls{b} = \cls{n - a}\), we have:
          \[
              \begin{aligned}
                  \cls{a} \oplus \cls{b} & = \cls{a} \oplus \cls{n - a} \\
                                         & = \cls{a + n - a}            \\
                                         & = \cls{n}                    \\
                                         & =       \cls{0}
              \end{aligned}
          \]
          as required, and commutativity gives us \(\cls{b} \oplus \cls{a} = \cls{0}\).

          \subsubsection*{Closure under \(\oplus\)}

          By definition, we have that
          \[
              \cls{a} \oplus \cls{b} = \cls{a + b}
          \]

          Since \(\Z_n\) is the set of congruence classes \(\cls{0}, \cls{1}, \ldots, \cls{n-1}\), and
          every integer has a unique representation modulo \(n\), then given \(a + b \in \Z\), their congruence class
          \(\cls{a + b} \in \Z_n\).

    \item[b.]

          We now define another operation \(\otimes\) for all \(\cls{a}, \cls{b} \in \Z_n\),
          \[
              \cls{a} \otimes \cls{b} = \cls{a \times b},
          \]
          where \(\times\) represents the usual multiplication in \(\Z\).

          We then have the following multiplication table for \(\Z_5 \setminus \{\cls{0}\}\) under \(\otimes\):
          \[
              \begingroup
              \renewcommand{\arraystretch}{1.3}
              \begin{array}{c|ccccc}
                  \otimes & \cls{1} & \cls{2} & \cls{3} & \cls{4} \\
                  \hline
                  \cls{1} & \cls{1} & \cls{2} & \cls{3} & \cls{4} \\
                  \cls{2} & \cls{2} & \cls{4} & \cls{1} & \cls{3} \\
                  \cls{3} & \cls{3} & \cls{1} & \cls{4} & \cls{2} \\
                  \cls{4} & \cls{4} & \cls{3} & \cls{2} & \cls{1} \\
              \end{array}
              \endgroup
          \]

          It follows that \(\Z_5 \setminus \{\cls{0}\}\) is closed under \(\otimes\), with the neutral element
          \(\cls{1}\). From the symmetry about the diagonal, we can immediately conclude that \(\otimes\) commutes.  For
          the inverse, we find the column (resp. row) that yields \(\cls{1}\) for a given row (resp. column), noting
          that \(\cls{1}\) appears in every row (resp. column).  For associativity, we note that for any three
          \(\cls{a}, \cls{b}, \cls{c} \in \Z_n \setminus \{\cls{0}\}\), both \(\cls{a} \otimes (\cls{b} \otimes
          \cls{c})\) and \((\cls{a} \otimes \cls{b}) \otimes \cls{c}\) yield the same result.  Hence, \((\Z_5 \setminus
          \{\cls{0}\}, \otimes)\) forms an Abelian group.

    \item[c.] We find that \((\Z_8 \setminus \{\cls{0}\}, \otimes)\) does not form a group, since \( \cls{2} \otimes
          \cls{4} = \cls{0} \), so closure is not satisfied.

    \item[d.] Bézout's lemma tells us that two integers \(a\) and \(b\) are relatively prime (that is, \(\gcd(a, b) = 1\)) if
          and only if there exist two integers \(u\) and \(v\) such that \(au + bv = 1\).

          Show that \((\Z_n \setminus \{\cls{0}\}, \otimes)\) is a group if and only if \(n \in \N \setminus \{0\}\) is
          prime.

          \begin{proof}[Proof]
              The neutral element is \(\cls{1} \in \Z_n \setminus \{\cls{0}\}\), given that for all \(\cls{a} \in \Z_n
              \setminus \{\cls{0}\}\):
              \[
                  \begin{aligned}
                      \cls{a} \otimes \cls{1} = \cls{a \times 1} = \cls{a} & \quad \textrm{and} \\
                      \cls{1} \otimes \cls{a} = \cls{1 \times a} = \cls{a} & .
                  \end{aligned}
              \]

              For all \(\cls{a}, \cls{b}, \cls{c} \in \Z_n \setminus \{\cls{0}\}\), we have associativity (which follows
              directly from associativity of integer multiplication):
              \[
                  \begin{aligned}
                      (\cls{a} \otimes \cls{b}) \otimes \cls{c}
                      = \cls{a \times b \times c}
                      = \cls{a} \otimes (\cls{b} \otimes \cls{c}).
                  \end{aligned}
              \]

              If \(n\) is composite, then there exist \(\cls{p}, \cls{q} \in \Z_n \setminus \{\cls{0}\}\) such that
              \(\cls{p} \otimes \cls{q} = \cls{0}\); that is, \(\Z_n \setminus \{\cls{0}\}\) contains zero divisors, and
              is not closed under \(\otimes\).  Conversely, if \(n\) is prime then no such \(\cls{p}\) or \(\cls{q}\)
              exist; \(\Z_n \setminus \{\cls{0}\}\) contains no zero divisors and is closed under \(\otimes\).

              Finally, for the existence of an inverse for all \(\cls{a} \in \Z_n \setminus \{\cls{0}\}\), we have from
              Bézout's lemma that \(a\) and \(n\) are relatively prime if and only if there exist two integers \(u\) and
              \(v\) such that \(au + nv = 1\).  Reducing both sides modulo \(n\), we have
              \[
                  au \equiv 1 \mod n,
              \]
              which tells us that \(u\) exists if and only if \(n\) is prime.  Restated:
              \[
                  \left (
                  \forall\, \cls{a} \in \Z_n \setminus \{ \cls{0} \},\quad
                  \exists\, \cls{u} \in \Z_n \setminus \{ \cls{0} \}:\quad
                  \cls{a} \otimes \cls{u} = \cls{1}
                  \right )
                  \iff n \text{ is prime}.
              \]

              Concluding, a neutral element always exists; associativity always holds; closure and the existence of
              inverses hold if and only if \(n\) is prime.  Therefore, \((\Z_n \setminus \{\cls{0}\}, \otimes)\) forms a
              group if and only if \(n\) is prime.

          \end{proof}

    \item[2.3] Consider the set \(\G\) of \(3 \times 3\) matrices, defined as follows
          \[
              \G = \left \{
              \begin{bmatrix}
                  1 & x & z \\
                  0 & 1 & y \\
                  0 & 0 & 1
              \end{bmatrix}
              \in \R^3
              \;\middle|\;
              x, y, z \in \R
              \right \}
          \]
          We define \(\cdot\) as the standard matrix multiplication.  Is \((\G, \cdot)\) a group?  If yes, is it
          Abelian?

          For \(a, b, c, x, y, z \in \R\), let:
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  1 & a & c \\
                  0 & 1 & b \\
                  0 & 0 & 1
              \end{bmatrix}
              \quad
              \mathbf{B} =
              \begin{bmatrix}
                  1 & x & z \\
                  0 & 1 & y \\
                  0 & 0 & 1
              \end{bmatrix}
          \]
          Then we have closure:
          \[
              \mathbf{B} \cdot \mathbf{A} =
              \begin{bmatrix}
                  1 & a + x & c + bx + z \\
                  0 & 1     & b + y      \\
                  0 & 0     & 1
              \end{bmatrix}
              \in \G,
          \]
          and
          \[
              \mathbf{A} \cdot \mathbf{B} =
              \begin{bmatrix}
                  1 & a + x & c + ay + z \\
                  0 & 1     & b + y      \\
                  0 & 0     & 1
              \end{bmatrix}
              \in \G.
          \]

          Associativity follows from associativity of standard matrix multiplication.  Similarly, we have the standard identity
          matrix, \(\mathbf{I} \in \G\).  For \(\mathbf{A}\) defined as above, we have its inverse:
          \[
              \mathbf{A}^{-1} =
              \begin{bmatrix}
                  1 & -a & ab - c \\
                  0 & 1  & -b     \\
                  0 & 0  & 1
              \end{bmatrix}
              \in \G.
          \]
          Verifying, we have
          \[
              \mathbf{A} \cdot \mathbf{A}^{-1} =
              \begin{bmatrix}
                  1 & a - a & ab -c -ab + c \\
                  0 & 1     & b - b         \\
                  0 & 0     & 1
              \end{bmatrix}
              =
              \begin{bmatrix}
                  1 & 0 & 0 \\
                  0 & 1 & 0 \\
                  0 & 0 & 1
              \end{bmatrix}
              = \mathbf{I}
          \]
          and
          \[
              \mathbf{A}^{-1} \cdot \mathbf{A} =
              \begin{bmatrix}
                  1 & a - a & c - ab + ab - c \\
                  0 & 1     & b - b           \\
                  0 & 0     & 1
              \end{bmatrix}
              =
              \begin{bmatrix}
                  1 & 0 & 0 \\
                  0 & 1 & 0 \\
                  0 & 0 & 1
              \end{bmatrix}
              = \mathbf{I}
          \]
          as desired.  We saw above that, in general, multiplication of \(\mathbf{A}, \mathbf{B} \in \G\) does not commute.
          We therefore conclude that \((\G, \cdot)\) is a group, but not Abelian.

          \pagebreak

    \item[2.4]

    \item[a.]
          \[
              \begin{bmatrix}
                  1 & 2 \\
                  4 & 5 \\
                  7 & 8
              \end{bmatrix}
              \begin{bmatrix}
                  1 & 1 & 0 \\
                  0 & 1 & 1 \\
                  1 & 0 & 1
              \end{bmatrix}
          \]
          is not defined.

    \item[b.]
          \[
              \begin{bmatrix}
                  1 & 2 & 3 \\
                  4 & 5 & 6 \\
                  7 & 8 & 9
              \end{bmatrix}
              \begin{bmatrix}
                  1 & 1 & 0 \\
                  0 & 1 & 1 \\
                  1 & 0 & 1
              \end{bmatrix}
              =
              \begin{bmatrix}
                  4  & 3  & 5  \\
                  10 & 9  & 11 \\
                  16 & 15 & 17
              \end{bmatrix}
          \]

    \item[c.]
          \[
              \begin{bmatrix}
                  1 & 1 & 0 \\
                  0 & 1 & 1 \\
                  1 & 0 & 1
              \end{bmatrix}
              \begin{bmatrix}
                  1 & 2 & 3 \\
                  4 & 5 & 6 \\
                  7 & 8 & 9
              \end{bmatrix}
              =
              \begin{bmatrix}
                  5  & 7  & 9  \\
                  11 & 13 & 15 \\
                  8  & 10 & 12
              \end{bmatrix}
          \]

    \item[d.]
          \[
              \begin{bmatrix}
                  1 & 2 & 1  & 2  \\
                  4 & 1 & -1 & -4 \\
              \end{bmatrix}
              \begin{bmatrix}
                  0 & 3  \\
                  1 & -1 \\
                  2 & 1  \\
                  5 & 2
              \end{bmatrix}
              =
              \begin{bmatrix}
                  14  & 2 \\
                  -21 & 2 \\
              \end{bmatrix}
          \]

    \item[e.]
          \[
              \begin{bmatrix}
                  0 & 3  \\
                  1 & -1 \\
                  2 & 1  \\
                  5 & 2
              \end{bmatrix}
              \begin{bmatrix}
                  1 & 2 & 1  & 2  \\
                  4 & 1 & -1 & -4 \\
              \end{bmatrix}
              =
              \begin{bmatrix}
                  12 & 3  & -3 & -12 \\
                  -3 & 1  & 2  & 6   \\
                  6  & 5  & 1  & 0   \\
                  13 & 12 & 3  & 2
              \end{bmatrix}
          \]

          \pagebreak

    \item[2.5] Find the set \(\mathcal{S}\) of all solutions in \(x\) of the following inhomogeneous systems
          \(\mathbf{A}\mathbf{x} = \mathbf{b}\), where \(\mathbf{A}\) and \(\mathbf{b}\) are defined as follows:

    \item[a.]
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{}i{2}i{3}i{3}i{3}@{\;\;}}
                      1 & 1  & -1 & -1 \\
                      2 & 5  & -7 & -5 \\
                      2 & -1 & 1  & 3  \\
                      5 & 2  & -4 & 2
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{b} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;\;}}
                      1 \\ -2 \\ 4  \\ 6
                  \end{array}
              \end{bmatrix}
          \]

          Constructing the augmented matrix, \(\tilde{\mathbf{A}}\), and row-reducing,
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1  & -1 & -1 & 1  \\
                          2 & 5  & -7 & -5 & -2 \\
                          2 & -1 & 1  & 3  & 4  \\
                          5 & 2  & -4 & 2  & 6
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 - 2r_1 \\
                      r_3 \mapsto r_3 - r_2  \\
                      r_4 \mapsto r_4 - 5r_1
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1  & -1 & -1 & 1  \\
                          0 & 3  & -5 & -3 & -4 \\
                          0 & -6 & 8  & 8  & 6  \\
                          0 & -3 & 1  & 7  & 1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto r_3 + 2r_2 \\
                      r_4 \mapsto r_4 + r_2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1 & -1 & -1 & 1  \\
                          0 & 3 & -5 & -3 & -4 \\
                          0 & 0 & -2 & 2  & -2 \\
                          0 & 0 & -4 & 4  & 2
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_4 \mapsto r_4 - 2r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{2}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & 1 & -1 & -1 & 1  \\
                          0 & 3 & -5 & -3 & -4 \\
                          0 & 0 & -2 & 2  & -2 \\
                          0 & 0 & 0  & 0  & 6
                      \end{array}
                  \end{bmatrix}
                   & \quad
              \end{aligned}
          \]
          we find that this system \(\mathbf{A}\mathbf{x} = \mathbf{b}\), has no solutions for \(\mathbf{x}\), since the
          final row of the augmented matrix corresponds to the inconsistent equation in the entries of \(\mathbf{x}\),
          \(0 = 6\).  This tells us that \(\mathbf{b} \notin \Img(\mathbf{A})\).

          If instead we were solving the \emph{homogeneous} system, \(\mathbf{A}\mathbf{x} = \mathbf{0}\), then we
          \emph{would} find solutions for \(\mathbf{x}\), namely the null space of \(\mathbf{A}\), which is nontrivial
          since we know \(\mathbf{A}\) is less than full rank.

          Similarly, if instead \(\mathbf{b} \in \Img(\mathbf{A})\), the solutions for \(\mathbf{x}\) in
          \(\mathbf{A}\mathbf{x} = \mathbf{b}\) would form an affine subspace in \(\R^4\), namely the null space of
          \(\mathbf{A}\) shifted by any particular solution; that is
          \[
              \left \{ \mathbf{x} \in \R^4 \mid \mathbf{A}\mathbf{x} = \mathbf{b} \right \} =  \mathbf{x}_0 + \Null(\mathbf{A})
          \]

          \pagebreak

    \item[b.]
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}i{3}i{2}i{3}i{3}@{\;\;}}
                      1  & -1 & 0 & 0  & 1  \\
                      1  & 1  & 0 & -3 & 0  \\
                      2  & -1 & 0 & 1  & -1 \\
                      -1 & 2  & 0 & -2 & -1
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{b} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;\;}}
                      3 \\ 6 \\ 5 \\ -1
                  \end{array}
              \end{bmatrix}
          \]

          Constructing the augmented matrix, \(\tilde{\mathbf{A}}\), and row-reducing,
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1  & -1 & 0 & 0  & 1  & 3  \\
                          1  & 1  & 0 & -3 & 0  & 6  \\
                          2  & -1 & 0 & 1  & -1 & 5  \\
                          -1 & 2  & 0 & -2 & -1 & -1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 - r_1   \\
                      r_3 \mapsto r_3 - 2 r_2 \\
                      r_4 \mapsto r_4 + r_2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & -1 & 0 & 0  & 1  & 3  \\
                          0 & 2  & 0 & -3 & -1 & 3  \\
                          0 & -3 & 0 & 7  & -1 & -7 \\
                          0 & 3  & 0 & -5 & -1 & 5
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto (2r_3 + 3r_2) / 5 \\
                      r_4 \mapsto (r_4 + r_3) / 2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & -1 & 0 & 0  & 1  & 3  \\
                          0 & 2  & 0 & -3 & -1 & 3  \\
                          0 & 0  & 0 & 1  & -1 & -1 \\
                          0 & 0  & 0 & 1  & -1 & -1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_4 \mapsto r_4 - r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{3}i{3}i{3}i{3}i{3}|i{3}@{\;\;}}
                          1 & -1 & 0 & 0  & 1  & 3  \\
                          0 & 2  & 0 & -3 & -1 & 3  \\
                          0 & 0  & 0 & 1  & -1 & -1 \\
                          0 & 0  & 0 & 0  & 0  & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                  \end{array}
              \end{aligned}
          \]

          Equivalently, in the components of \(\mathbf{x}\),
          \[
              x_1
              \begin{bmatrix}
                  \begin{array}{@{\;}i{1}@{\;}}
                      1 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_2
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      -1 \\ 2  \\ 0  \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_3
              \begin{bmatrix}
                  \begin{array}{@{\;}i{1}@{\;}}
                      0 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_4
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      0 \\ -3 \\ 1  \\ 0
                  \end{array}
              \end{bmatrix}
              +
              x_5
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      1 \\ -1 \\ -1 \\ 0
                  \end{array}
              \end{bmatrix}
              =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\;}}
                      3 \\ 3  \\ -1 \\ 0
                  \end{array}
              \end{bmatrix}
          \]

          This gives us the following particular solution and solution set,
          \[
              \mathbf{x}_0 =
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      6 \\ 6 \\ 0 \\ 2 \\ 3
                  \end{array}
              \end{bmatrix}
              \quad
              \left \{
              \mathbf{x} \in \R^5
              \; \middle | \;
              \mathbf{x} =
              \mathbf{x}_0
              + \lambda_1
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      0 \\ 0 \\ 1 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              +
              \lambda_2
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      1 \\ 2 \\ 0 \\ 1 \\ 1
                  \end{array}
              \end{bmatrix}
              ,\;
              \lambda_1, \lambda_2 \in \R
              \right \}
          \]

          \pagebreak

    \item[2.6] Using Gaussian elimination, find all solutions of the inhomogeneous system
          \(\mathbf{A}\mathbf{x} = \mathbf{b}\), where
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}i{1}i{1}i{1}i{1}i{1}@{\,}}
                      0 & 1 & 0 & 0 & 1 & 0 \\
                      0 & 0 & 0 & 1 & 1 & 0 \\
                      0 & 1 & 0 & 0 & 0 & 1
                  \end{array}
              \end{bmatrix}
              \quad
              \mathbf{b} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\,\;}}
                      2 \\ -1 \\ 1
                  \end{array}
              \end{bmatrix}
          \]

          Constructing the augmented matrix, \(\tilde{\mathbf{A}}\), and eliminating,
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{\,}i{2}i{3}i{3}i{3}i{3}i{3}@{\quad}|i{3}@{\;\;}}
                          0 & 1 & 0 & 0 & 1 & 0 & 2  \\
                          0 & 0 & 0 & 1 & 1 & 0 & -1 \\
                          0 & 1 & 0 & 0 & 0 & 1 & 1
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto r_1 - r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\,}i{2}i{3}i{3}i{3}i{3}i{3}@{\quad}|i{3}@{\;\;}}
                          0 & 1 & 0 & 0 & 1 & 0  & 2  \\
                          0 & 0 & 0 & 1 & 1 & 0  & -1 \\
                          0 & 0 & 0 & 0 & 1 & -1 & 1
                      \end{array}
                  \end{bmatrix}
              \end{aligned}
          \]
          yields the following solution set
          \[
              \left \{
              \mathbf{x} \in \R^6
              \; \middle | \;
              \mathbf{x} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\,\;}}
                      0 \\ 2  \\ 0  \\ -1 \\ 0  \\ -1
                  \end{array}
              \end{bmatrix}
              + \lambda_1
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              + \lambda_2
              \begin{bmatrix}
                  \begin{array}{@{\,}i{1}@{\,}}
                      0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0
                  \end{array}
              \end{bmatrix}
              + \lambda_3
              \begin{bmatrix}
                  \begin{array}{@{}i{3}@{\,\;}}
                      0 \\ 1  \\ 0  \\ 1  \\ -1 \\ 1
                  \end{array}
              \end{bmatrix}
              ,\;
              \lambda_1, \lambda_2, \lambda_3 \in \R
              \right \}
          \]

          \pagebreak

    \item[2.7] Find all solutions in \(\mathbf{x} = \begin{bmatrix}x_1 \\ x_2 \\ x_3\end{bmatrix} \in \R^3\) of the
          equation system \(\mathbf{A}\mathbf{x} = 12\mathbf{x}\), where
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  6 & 4 & 3 \\
                  6 & 0 & 9 \\
                  0 & 8 & 0
              \end{bmatrix}
              \quad \textrm{and} \quad
              \sum_{i = 1}^{3} x_i = 1.
          \]

          Rearranging, we wish to solve \((\mathbf{A} - 12 \mathbf{I}) \mathbf{x} = \mathbf{0}\), subject to the sum
          over the components of \(\mathbf{x}\). Let \(\mathbf{B} = \mathbf{A} - 12 \mathbf{I}\), then we can construct
          an augmented matrix, \(\tilde{\mathbf{B}}\), which captures all the constraints (in particular, the first row
          encodes the constraint that \(x_1 + x_2 + x_3 = 1\)):
          \[
              \begin{aligned}
                  \tilde{\mathbf{B}} =
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1  & 1   & 1   & 1 \\
                          -6 & 4   & 3   & 0 \\
                          6  & -12 & 9   & 0 \\
                          0  & 8   & -12 & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto r_3 + r_2
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1  & 1  & 1   & 1 \\
                          -6 & 4  & 3   & 0 \\
                          0  & -8 & 12  & 0 \\
                          0  & 8  & -12 & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_2 \mapsto r_2 + 6r_1 \\
                      r_3 \mapsto -r_3 / 4   \\
                      r_4 \mapsto r_4 + r_3
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1 & 1  & 1  & 1 \\
                          0 & 10 & 9  & 6 \\
                          0 & 2  & -3 & 0 \\
                          0 & 0  & 0  & 0
                      \end{array}
                  \end{bmatrix}
                   & \quad
                  \begin{array}{l}
                      r_3 \mapsto (r_2 - 5r_3) / 6
                  \end{array}
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{}i{4}i{4}i{4}@{\quad}|i{2}@{\;\;}}
                          1 & 1  & 1 & 1 \\
                          0 & 10 & 9 & 6 \\
                          0 & 0  & 4 & 1 \\
                          0 & 0  & 0 & 0
                      \end{array}
                  \end{bmatrix}
              \end{aligned}
          \]

          From this, we find a single solution,
          \(
          \mathbf{x}_0 =
          \dfrac{1}{8}
          \begin{bmatrix}
              3 & 3 & 2
          \end{bmatrix}^{\top}.
          \)

          Examining the last three rows of the reduced \(\tilde{\mathbf{B}}\), we can conclude that \(\rank(\mathbf{B}) =
          2\), and therefore \(\dim(\Null(\mathbf{B})) = 1\).  That is, the null space of \(\mathbf{B}\) is a line,
          which intersects with \(\mathbf{1} \in \R^3\) at a single point, \(\mathbf{x}_0\).  Specifically, we have
          \[
              \Null(\mathbf{B}) = \left \{ \mathbf{x} \in \R^3: \mathbf{x} = \lambda
              \begin{bmatrix}
                  3 \\ 3 \\ 2
              \end{bmatrix}
              ,\;
              \lambda \in \R
              \right \}.
          \]

    \item[2.8]

    \item[a.]
          Given
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  2 & 3 & 4 \\
                  3 & 4 & 5 \\
                  4 & 5 & 6
              \end{bmatrix}
          \]
          we find that \(\mathbf{A}\) has no inverse, since \(\det(\mathbf{A}) = 0\).

    \item[b.]
          Given
          \[
              \mathbf{A} =
              \begin{bmatrix}
                  1 & 0 & 1 & 0 \\
                  0 & 1 & 1 & 0 \\
                  1 & 1 & 0 & 1 \\
                  1 & 1 & 1 & 0
              \end{bmatrix}
          \]
          we find
          \[
              \det(\mathbf{A}) = \det \left (
              \begin{bmatrix}
                      1 & 1 & 0 \\
                      1 & 0 & 1 \\
                      1 & 1 & 0
                  \end{bmatrix}
              \right )
              + \det \left (
              \begin{bmatrix}
                      0 & 0 & 1 \\
                      1 & 1 & 1 \\
                      0 & 1 & 1
                  \end{bmatrix}
              \right )
              = 0 + 1
              = 1.
          \]

          We look for solutions to the following:
          \[
              \begin{bmatrix}
                  1 & 0 & 1 & 0 \\
                  0 & 1 & 1 & 0 \\
                  1 & 1 & 0 & 1 \\
                  1 & 1 & 1 & 0
              \end{bmatrix}
              \begin{bmatrix}
                  a & b & c & d \\
                  e & f & g & h \\
                  i & j & k & l \\
                  m & n & o & p
              \end{bmatrix}
              \\
              =
              \begin{bmatrix}
                  a + i     & b + j     & c + k     & d + l     \\
                  e + i     & f + j     & g + k     & h + l     \\
                  a + e + m & b + f + n & c + g + o & d + h + p \\
                  a + e + i & b + f + j & c + g + k & d + h + l
              \end{bmatrix}
              =
              \mathbf{I}
          \]

          Solving each system of four equations in four variables gives us:
          \[
              \mathbf{A}^{-1} =
              \begin{bmatrix}
                  \begin{array}{@{}i{3}i{3}i{3}i{3}@{\;\;}}
                      0  & -1 & 0 & 1  \\
                      -1 & 0  & 0 & 1  \\
                      1  & 1  & 0 & -1 \\
                      1  & 1  & 1 & -2
                  \end{array}
              \end{bmatrix}
          \]

          Alternatively, we can augment \(\mathbf{A}\) with the identity matrix \(\mathbf{I}\) and reduce:
          \[
              \begin{aligned}
                  \tilde{\mathbf{A}} =
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 1 & 0 & 1 & 0 & 0 & 0 \\
                          0 & 1 & 1 & 0 & 0 & 1 & 0 & 0 \\
                          1 & 1 & 0 & 1 & 0 & 0 & 1 & 0 \\
                          1 & 1 & 1 & 0 & 0 & 0 & 0 & 1
                      \end{array}
                  \end{bmatrix}
                   &
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 1  & 0  & 1  & 0 & 0  & 0 \\
                          0 & 1 & 1  & 0  & 0  & 1 & 0  & 0 \\
                          0 & 1 & -1 & 1  & -1 & 0 & 1  & 0 \\
                          0 & 0 & 1  & -1 & 0  & 0 & -1 & 1
                      \end{array}
                  \end{bmatrix}
                   &
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 1 & 0  & 1 & 0 & 0  & 0  \\
                          0 & 1 & 1 & 0  & 0 & 1 & 0  & 0  \\
                          0 & 0 & 2 & -1 & 1 & 1 & -1 & 0  \\
                          0 & 0 & 0 & 1  & 1 & 1 & 1  & -2
                      \end{array}
                  \end{bmatrix}
                   &
                  \\
                  \rightsquigarrow
                  \begin{bmatrix}
                      \begin{array}{@{\negmedspace}i{3}i{3}i{3}i{3}@{\quad}|@{\quad}i{3}i{3}i{3}i{3}@{\;\;\;}}
                          1 & 0 & 0 & 0 & 0  & -1 & 0 & 1  \\
                          0 & 1 & 0 & 0 & -1 & 0  & 0 & 1  \\
                          0 & 0 & 1 & 0 & 1  & 1  & 0 & -1 \\
                          0 & 0 & 0 & 1 & 1  & 1  & 1 & -2
                      \end{array}
                  \end{bmatrix}
                   & = \begin{bmatrix}
                           \;\mathbf{I} \;|\; \mathbf{A}^{-1} \,
                       \end{bmatrix}
              \end{aligned}
          \]

          \pagebreak

    \item[2.9] Which of the following are subspaces of \(\R^3\)?

          \(A = \{ (\lambda, \lambda + \mu^3, \lambda - \mu^3 ) \mid \lambda, \mu \in \R \}\)

          \(B = \{ (\lambda^2, -\lambda^2, 0) \mid \lambda \in \R \}\)

          \(C = \{ (\eta_1, \eta_2, \eta_3) \in \R^3 \mid \eta_1 - 2 \eta_2 + 3 \eta_3 = \gamma, \; \gamma \in \R \}\)

          \(D = \{ (\kappa_1, \kappa_2, \kappa_3) \in \R^3 \mid \kappa_2 \in \Z \}\)

          \begin{enumerate}
              \item[a.] \(A\) is \emph{not} a subspace of \(\R^3\), since it is not possible to express all members of \(A\) as a
                    linear combination of a basis.

              \item[b.] \(B\) is also \emph{not} a subspace of \(\R^3\), for the same reason.

              \item[c.] \(C\) is a subspace of \(\R^3\) if and only if \(\gamma = 0\), since otherwise \(C\) does not contain the
                    origin.  In the case that \(\gamma\) \emph{does} equal \(0\), then \(C = \Span((1, 2, 1))\).

              \item[d.] \(D\) is \emph{not} a subspace of \(\R^3\), since \(D\) is not closed under scalar multiplication by
                    \(\lambda \in \R\).

          \end{enumerate}

    \item[2.10]

          \begin{enumerate}
              \item[a.] The set of vectors \(\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3\) is linearly dependent, as found
                    by constructing the matrix \(\begin{bmatrix}
                        \mathbf{x}_1 \; \mathbf{x}_2 \; \mathbf{x}_3
                    \end{bmatrix}\) and row-reducing:

                    \[
                        \begin{bmatrix}
                            \begin{array}{@{\negthinspace}i{3}i{3}i{3}@{\;\;}}
                                2  & 1  & 3  \\
                                -1 & 1  & -3 \\
                                3  & -2 & 8
                            \end{array}
                        \end{bmatrix}
                        \rightsquigarrow
                        \begin{bmatrix}
                            \begin{array}{@{\negthickspace}i{3}i{3}i{3}@{\;\;}}
                                1 & 2 & 0  \\
                                0 & 1 & -1 \\
                                0 & 0 & 0
                            \end{array}
                        \end{bmatrix}
                    \]
                    The final row of all zeros indicates the matrix has rank $2 < 3$, so the columns are linearly dependent.

              \item[b.] The set of vectors \(\mathbf{x}_1, \mathbf{x}_2, \mathbf{x}_3\) is linearly independent, as found
                    by constructing the matrix \(\begin{bmatrix}
                        \mathbf{x}_1 \; \mathbf{x}_2 \; \mathbf{x}_3
                    \end{bmatrix}\) and row-reducing:
                    \[
                        \begin{bmatrix}
                            1 & 1 & 1 \\
                            2 & 1 & 0 \\
                            1 & 0 & 0 \\
                            0 & 1 & 1 \\
                            0 & 1 & 1
                        \end{bmatrix}
                        \rightsquigarrow
                        \begin{bmatrix}
                            1 & 0 & 0 \\
                            0 & 1 & 0 \\
                            0 & 0 & 1 \\
                            0 & 0 & 0 \\
                            0 & 0 & 0
                        \end{bmatrix}
                    \]
                    revealing three pivot columns. The matrix therefore has full column rank \(3\), and its column
                    vectors are linearly independent.

          \end{enumerate}

\end{enumerate}

\end{document}
